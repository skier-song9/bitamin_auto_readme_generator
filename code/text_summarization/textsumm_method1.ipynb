{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "H-8f48Oxetyi"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import openai\n",
        "import os\n",
        "import re\n",
        "from langchain_openai import ChatOpenAI\n",
        "import transformers\n",
        "from datasets import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "opxC6SYMisdl"
      },
      "outputs": [],
      "source": [
        "file_path = 'C:\\\\Users\\\\PC\\\\Desktop\\\\DoYoung\\\\DS\\\\github\\\\bitamin_auto_readme_generator\\\\data\\\\object_detection\\\\output\\\\ocr_samples_txt\\\\netflix_text.txt'\n",
        "\n",
        "with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        text = file.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "XXCSOd6ldbz4"
      },
      "outputs": [],
      "source": [
        "api_key_filepath = \"C:\\\\Users\\\\PC\\\\Desktop\\\\DoYoung\\\\DS\\\\비타민NLP_240701\\\\text_summarization\\\\openai_api_key.json\"\n",
        "with open(api_key_filepath, 'r') as f:\n",
        "    api_key = json.load(f)\n",
        "api_key = api_key['OPENAI_API_KEY']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "bcVtzndaqbXY"
      },
      "outputs": [],
      "source": [
        "os.environ['OPENAI_API_KEY'] = api_key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "llm_3 = ChatOpenAI(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    openai_api_key=os.environ['OPENAI_API_KEY']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "llm_4 = ChatOpenAI(\n",
        "    model=\"gpt-4o\",\n",
        "    openai_api_key=os.environ['OPENAI_API_KEY']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sX6DQDnrjrmI"
      },
      "source": [
        "### STEP1: 첫 5페이지의 텍스트만 추출"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "FfSysbcBi4xR"
      },
      "outputs": [],
      "source": [
        "end_marker = text.find('<p.6>')\n",
        "\n",
        "if end_marker != -1:\n",
        "    text5 = text[:end_marker]\n",
        "else:\n",
        "    text5 = text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yweVqcFOjzVb"
      },
      "source": [
        "### STEP2: 마크다운 형식으로 팀원, 주제, main topic 추출"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_cdttzzt_nX",
        "outputId": "76d701e8-8447-4dcc-cae8-9a70407d34d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<subject>Netflix Stock Price Prediction with News Topic & Sentiment</subject>\n",
            "<team>송규헌, 권도영, 이태경, 김서윤, 한진솔</team>\n",
            "<index>INTRODUCTION, DATA PREPROCESSING, MODELING, CONCLUSIONS AND LIMITATIONS</index>\n"
          ]
        }
      ],
      "source": [
        "def extract_information(text5):\n",
        "    prompt = f\"\"\"\n",
        "    Extract the following information from the provided text:\n",
        "    1. Name (excluding the team name, include all people listed)\n",
        "    2. Title (include the entire title as it appears in the text)\n",
        "    3. Main Topics (only main topics from the Table of Contents, excluding subtopics)\n",
        "\n",
        "    The Main Topics should be extracted from the section that follows headers such as 'TABLE OF CONTENTS', '목차 소개', or any similar variation.\n",
        "    Ensure that team member's name are not split into multiple lines. Name should be connected by commas if there are more than one.\n",
        "    Ensure that title is not cut off and is extracted in their entirety.\n",
        "    Exclude any subtopics or secondary information while extracting main topics.\n",
        "    Stop at the next page marker '<p.'.\n",
        "\n",
        "    Do not include any additional notes or explanations in the output.\n",
        "\n",
        "    Text: {text5}\n",
        "\n",
        "\n",
        "    Format the extracted information as follows:\n",
        "    <subject>title</subject>\n",
        "    <team>team members</team>\n",
        "    <index>main topics</index>\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    response = llm_4.invoke(prompt)\n",
        "    extracted_info = response.content.strip()\n",
        "    return extracted_info\n",
        "\n",
        "extracted_info = extract_information(text5)\n",
        "print(extracted_info)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "De0eBjj0BmuA"
      },
      "outputs": [],
      "source": [
        "main_topics_match = re.search(r'<index>(.*?)</index>', extracted_info, re.DOTALL)\n",
        "if main_topics_match:\n",
        "    main_topics = main_topics_match.group(1).strip()\n",
        "else:\n",
        "    main_topics = \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giYOigJxtK85"
      },
      "source": [
        "### STEP3: 전체 텍스트에서 대주제, 소주제, 핵심내용 추출"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "_ifc44eL-oka"
      },
      "outputs": [],
      "source": [
        "def extract_detailed_information(text, main_topics):\n",
        "    prompt = f\"\"\"\n",
        "    Extract detailed information for each main topic and its subtopics from the provided text.\n",
        "\n",
        "    Format the extracted information as follows:\n",
        "    <main>main topic</main>\n",
        "    <sub>subtopic</sub>\n",
        "    <content>content</content>\n",
        "\n",
        "    Use the main topics provided below:\n",
        "    {main_topics}\n",
        "    \n",
        "    The text is divided into pages using the format <p.number>. For example, page 2 is marked as <p.2>. \n",
        "    Make sure to extract text from all pages except for the first five pages to ensure no information is missed.\n",
        "    If any part of the text seems to be related to the main topics but is not included in the main topics list(main_topics), include it as a subtopic under the appropriate main topic.\n",
        "    Do not include any additional notes or explanations in the output.\n",
        "\n",
        "    Text: {text}\n",
        "    \"\"\"\n",
        "\n",
        "    response = llm_4.invoke(prompt)\n",
        "    extracted_details = response.content.strip()\n",
        "    return extracted_details"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuGr0wnJ-oiP",
        "outputId": "a9f05a4a-6f6c-4e7e-e04c-21a950a75af5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<main>INTRODUCTION</main>\n",
            "<sub>Background of topic selection</sub>\n",
            "<content>\n",
            "1. 뉴스가 주가 변동에 미치는 영향 탐구 \n",
            "   - 주가 예측에 뉴스를 활용할 수 있는지 탐구해보고자 함\n",
            "   - 뉴스 감성분석 및 토픽 모델링 결과를 사용하여 예측\n",
            "   - 뉴스 기사에서는 주로 한 기업에 대해 보도하고 있어 예측 대상은 한 개의 주식 종목으로 정함\n",
            "   - 뉴스 데이터를 직접 활용하여 주가를 예측하는 프로젝트는 많지 않아 직접 뉴스 데이터를 활용하고자 함\n",
            "2. 장기적인 추세를 고려할 수 있는 주가 예측 모델 구현\n",
            "   - 기존 프로젝트는 주로 예측 일수나 시퀀스 길이를 1~5로 설정함\n",
            "   - 단기적인 변동뿐만 아니라 장기적인 추세를 고려한 예측 결과를 얻고자 함\n",
            "   - 주가 예측 그래프가 실제 주가 그래프를 단순 평행 이동한 형태로 나타나는 문제를 해결하고자 함\n",
            "</content>\n",
            "<sub>Brief Project Introduction</sub>\n",
            "<content>\n",
            "   - [목표] 뉴스 데이터를 활용한 주가 예측 모델의 최적화 및 효율적인 파라미터 선정\n",
            "   - [주요 내용] 장기적인 추세 예측에 효과적인 모델 판별: LSTM VS GRU Vs Transformer\n",
            "   - 실험을 통한 모델 파라미터 튜닝\n",
            "   - 뉴스 감성분석과 토픽모델링의 주가 예측 유용성 검토\n",
            "   - 각 실험 결과 평가에 필요한 지표 선정\n",
            "   - [개발 환경] Colab\n",
            "</content>\n",
            "<sub>Data collection</sub>\n",
            "<content>\n",
            "1. 주가 데이터\n",
            "   - FinanceDataReader 라이브러리를 활용하여 NETFLIX 기업의 2018년 1월 2일 ~ 2023년 12월 29일 주가 데이터 수집\n",
            "   - 동일한 기간에 대한 핀터레스트, 메타플렛폼스, 스포티파이의 주가 데이터 수집\n",
            "2. 뉴스 데이터\n",
            "   - Stock News Ap를 활용하여 2018년 1월 2일부터 2023년 12월 29일 기간에 발행된 NETFLIX 기업과 관련된 뉴스 데이터 수집\n",
            "   - 웹 스크래핑을 통해 뉴스 수집 후 FinBERT와 BERTopic을 활용하여 감성 분석과 토픽 모델링 시도\n",
            "   - 시계열 예측에 집중하고 데이터셋의 정확도를 높이고자 Ap를 사용함\n",
            "</content>\n",
            "\n",
            "<main>DATA PREPROCESSING</main>\n",
            "<sub>Make derived Variable</sub>\n",
            "<content>\n",
            "   - RocRange Of Change 변화율, MAMoVing Average 이동 평균, SMA, 12OMA\n",
            "   - 이전 시점을 포함하여 rolling하는 변수이므로 생성된 파생변수의 첫 시점은 NaN 상태\n",
            "   - 2018년 데이터를 추가로 수집해 파생변수 생성에 활용\n",
            "</content>\n",
            "<sub>Add indicators</sub>\n",
            "<content>\n",
            "   - Technical Analysis Library : 금융 시계열 데이터 세트 시가, 마감, 고가, 저가, 거래량에 대한 기술 분석 라이브러리\n",
            "   - Bol-high: Bollinger Bands 상단 밴드, KCH: Keltner Channel High, VI: Negative Directional Movement Index\n",
            "   - Bol-low: Bollinger Bands 하단 밴드, KCL: Keltner Channel Low, +VI: Positive Directional Movement Index\n",
            "   - ADI: Accumulation/Distribution Index, KCM: Keltner Channel Middle, TRIX: Triple Exponential Moving Average\n",
            "   - OBV: On-Balance Volume, DCH: Donchian Channel High, MI: Mass Index, CMF: Chaikin Money Flow\n",
            "   - DCL: Donchian Channel Low, ECI: Commodity Channel Index, FI: Force Index, DCM: Donchian Channel Middle\n",
            "   - DPO: Detrended Price Oscillator, EOM: Ease of Movement, U: Ulcer Index, KST: Know Sure Thing\n",
            "   - VPT: Volume-Price Trend, SMA: Simple Moving Average, STC: Schaff Trend Cycle, NVI: Negative Volume Index\n",
            "   - EMA: Exponential Moving Average, RSI: Relative Strength Index, VMAP: Volume-Weighted Average Price\n",
            "   - WMA: Weighted Moving Average, SRSI: Stochastic RSI, ATR: Average True Range, MACD: Moving Average Convergence Divergence\n",
            "   - UO: Ultimate Oscillator, MFI: Money Flow Index, ADX: Average Directional Index\n",
            "   - 한국투자증권 mts에서 지원하는 37개 지표 선정\n",
            "</content>\n",
            "<sub>Peer Analysis</sub>\n",
            "<content>\n",
            "   - Netflix와 유사한 사업을 영위하고 있는 기업의 해당 기간 종가를 feature로 추가\n",
            "   - PINS의 경우 2019년 04월 22일에 최초 상장 = 상장 이전의 결측값은 최초 상장일의 종가 2499$를 기준으로 대체\n",
            "</content>\n",
            "<sub>Remove multicollinearity</sub>\n",
            "<content>\n",
            "   - Open, Close, High, Low, SMA, 12OMA, bol-high, bol-low 등 주가의 변화와 관련된 기본 지표 유지\n",
            "   - VMAP, BHB, BLB, KCH, KCL, KCM, DCH, DCL, DCM, SMA, EMA, WMA 등 주가 변화 관련 기본 지표들과 1에 가까운 상관관계를 가지는 보조 지표 Drop\n",
            "   - FB, PINS, SPOT Peer stock은 유지\n",
            "</content>\n",
            "<sub>Make derived variable for News Topics & Sentiment</sub>\n",
            "<content>\n",
            "   - Topics: Label Encoding, SMA 6OMA, 12OMA\n",
            "   - Sentiments: OneHot Encoding, 5MM, 6OMM, 12OMM\n",
            "   - 당일의 뉴스가 당일의 주가에 영향을 미칠 가능성은 적기 때문에 과거 뉴스의 영향력을 측정하기 위해 Moving Average Moving Mode로 추가\n",
            "</content>\n",
            "<sub>Dataset</sub>\n",
            "<content>\n",
            "   - stockOnly-df 1257*38\n",
            "   - total-df 1257*59\n",
            "</content>\n",
            "\n",
            "<main>MODELING</main>\n",
            "<sub>Time Series</sub>\n",
            "<content>\n",
            "   - 시간에 따른 데이터 패턴을 분석하여 미래 값을 예측\n",
            "   - Sequence Length W: 한 번에 모델에 입력되는 연속된 데이터의 수 Cinput data\n",
            "   - Predict Size K: 모델이 예측할 미래 데이터의 길이 output data\n",
            "   - 고정된 Window Size: W+k\n",
            "</content>\n",
            "<sub>Modeling</sub>\n",
            "<content>\n",
            "   - Step 1: Sequence Length = 60, Predict Size = 10\n",
            "   - 학습에 사용할 1개의 시퀀스 데이터 형태: 60개의 Sequence 데이터, 10개의 Predict Size 데이터\n",
            "   - Step 2: Define Model\n",
            "     - LSTM: 기존의 주가 예측 모델이 주로 LSTM을 사용했지만 주로 sequence length = 1, prediction size = 1로 예측하기 때문에 이 파라미터들을 바꿔서 예측해보는 것이 유의미할 것이라 생각\n",
            "     - GRU: 기존의 LSTM 모델의 복잡성을 간단화함으로써 문제점을 극복\n",
            "     - Transformer: NLP에서 좋은 성능을 보이는데 주가 예측에서도 유의미한 결과를 가져오는지 확인하기 위해 선택\n",
            "   - Step 3: Model Comparison\n",
            "     - 무엇을 target으로? TARGET = 'CLOSE' VS TARGET = 'ID-ROC'\n",
            "     - 뉴스 포함? 미포함? ONLY STOCK DATA VS TOTAL DATA\n",
            "     - LSTM VS GRU Vs Transformer\n",
            "</content>\n",
            "\n",
            "<main>CONCLUSIONS AND LIMITATIONS</main>\n",
            "<sub>Evaluation</sub>\n",
            "<content>\n",
            "   - 예측 평가기준: 시계열 모델의 손실함수로 MSE는 값이 너무 커서 RMSE를 선택\n",
            "   - 어떤 변수를 Target으로 예측하는 것이 좋을까? Close 종가 vs 1dLROC 일일 등락\n",
            "   - 뉴스 데이터는 예측에 유의미한 영향을 주는가? StockOnly-df VS total Df\n",
            "   - 어떤 모델이 예측에 가장 효과적인가? LSTM VS GRU VS Transformer\n",
            "</content>\n",
            "<sub>Select target variable</sub>\n",
            "<content>\n",
            "   - Close vs 1dLROC\n",
            "   - Dataset: stockOnly-df, model: LSTM, Seq size: 60, batch-size: 8, model size: 64\n",
            "   - Dataset: total-df, 모델: LSTM, seq-size: 60, batch size: 8, model size: 64\n",
            "   - Close를 직접 예측할 때보다 ROC로 예측하는 것이 추세 반영이 잘되는 것을 확인\n",
            "   - 시계열 예측에서 정상성을 확보해야 예측모델을 더욱 신뢰할 수 있기에 ROC로 Target 확정\n",
            "</content>\n",
            "<sub>Model Result</sub>\n",
            "<content>\n",
            "   - LSTM: Jloss = RMSE\n",
            "   - GRU: Jloss = RMSE\n",
            "   - Transformer: Jloss = RMSE\n",
            "</content>\n",
            "<sub>Compare each parameter</sub>\n",
            "<content>\n",
            "   - 세 모델 중 LSTM의 loss 평균값이 가장 작고 transformer의 loss 평균값이 가장 큼\n",
            "   - GRU 모델에서는 주식 데이터로만 사용한 경우, LSTM과 transformer 모델에서는 뉴스 데이터를 포함한 데이터셋을 사용한 경우 loss 평균값이 더 작음\n",
            "   - Loss값은 Sequence_size, Batch-size는 값이 작을수록 유의미한 결과를 나타내고 Model Size에서는 LSTM, Transformer 모두 64에서 유의미했지만 GRU에서는 128에서 유의미한 결과를 보임\n",
            "</content>\n",
            "<sub>Best parameter for each model</sub>\n",
            "<content>\n",
            "   - Validation loss를 기준으로 모델별로 최적의 파라미터 조합을 선정하여 50번 반복 -> 평균값으로 경향성과 오차율을 파악 후 최종 모델 선정\n",
            "   - [LSTM] stock-only 데이터셋 seq: 30, batch: 8, model: 64, 평균 오차율: 185%\n",
            "   - [GRU] total 데이터셋 seq: 30, batch: 8, model: 128, 평균 오차율: 166%\n",
            "   - [Transformer] total 데이터셋 seq: 30, batch: 8, model: 64, 평균 오차율: 162%\n",
            "</content>\n",
            "<sub>Limitations</sub>\n",
            "<content>\n",
            "   - 금융 시장에서는 예상치 못한 사건이 발생하는 일이 많아 예측에 어려움이 있음\n",
            "   - 수치만으로 모델의 성능을 평가하기 어려워 일일이 예측 그래프를 확인해야 함\n",
            "   - 실험 결과를 비교하는데 시간 소요\n",
            "   - 뉴스 Topic NLP로 감성분석과 토픽모델링을 시도하였지만 시퀀스 길이 문제와 정확도를 높이는 것에 한계가 있어 Ap를 사용\n",
            "   - 일반적인 예측의 경우 5%의 오차가 좋은 평가를 받을 수 있으나 주식 시장에서 5% 오차는 큰 손실 또는 큰 이익 -> 예측 성능이 5% 이하로 나온 모델이라 할지라도 검토가 필요\n",
            "</content>\n"
          ]
        }
      ],
      "source": [
        "detailed_info = extract_detailed_information(text, main_topics)\n",
        "print(detailed_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wv1r7VOaCs8O"
      },
      "source": [
        "### STEP4: 요약"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w58Tuw5v-ofs",
        "outputId": "e9d576a6-6852-4885-8aeb-60e004e17a0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<main>INTRODUCTION</main>\n",
            "<sub>Background of topic selection</sub>\n",
            "<content>이 프로젝트는 뉴스가 주가 변동에 미치는 영향을 탐구하고, 이를 활용해 주가를 예측하는 것을 목표로 한다. 뉴스 감성분석과 토픽 모델링을 통해 특정 기업의 주가를 예측하며, 기존 프로젝트보다 더 긴 예측 기간을 고려해 장기적인 추세도 반영하고자 한다. 또한, 단순한 평행 이동 형태의 예측 문제를 해결하고자 한다.</content>\n",
            "<sub>Brief Project Introduction</sub>\n",
            "<content>목표는 뉴스 데이터를 활용해 주가 예측 모델을 최적화하고 효율적인 파라미터를 선정하는 것이다. 주요 내용은 LSTM, GRU, Transformer 모델의 장기 추세 예측 성능을 비교하고, 실험을 통해 모델 파라미터를 튜닝하는 것이다. 또한 뉴스 감성분석과 토픽모델링이 주가 예측에 얼마나 유용한지 검토하며, 실험 결과 평가에 필요한 지표를 선정한다. 개발 환경으로는 Colab을 사용한다.</content>\n",
            "<sub>Data collection</sub>\n",
            "<content>1. 주가 데이터: \n",
            "   - FinanceDataReader 라이브러리를 사용해 2018년 1월 2일부터 2023년 12월 29일까지 NETFLIX, 핀터레스트, 메타플렛폼스, 스포티파이의 주가 데이터를 수집.\n",
            "\n",
            "2. 뉴스 데이터:\n",
            "   - Stock News Ap를 통해 같은 기간 동안 NETFLIX 관련 뉴스 데이터를 수집.\n",
            "   - 웹 스크래핑 후 FinBERT와 BERTopic을 활용해 감성 분석과 토픽 모델링을 시도.\n",
            "   - 시계열 예측과 데이터셋의 정확도를 높이기 위해 Ap를 사용.</content>\n",
            "\n",
            "<main>DATA PREPROCESSING</main>\n",
            "<sub>Make derived Variable</sub>\n",
            "<content>변화율(Roc), 이동 평균(MA), 단순 이동 평균(SMA), 12OMA 등의 파생변수를 생성할 때, 이전 시점을 포함한 rolling 변수가 사용되어 첫 시점은 NaN이 된다. 2018년 데이터를 추가 수집하여 이러한 파생변수 생성을 보완한다.</content>\n",
            "<sub>Add indicators</sub>\n",
            "<content>금융 시계열 데이터 분석 라이브러리에서는 시가, 마감, 고가, 저가, 거래량에 대한 다양한 기술 분석 지표를 제공합니다. 주요 지표로는 Bollinger Bands, Keltner Channel, Directional Movement Index, Accumulation/Distribution Index, Triple Exponential Moving Average, On-Balance Volume, Donchian Channel, Commodity Channel Index, Force Index, Detrended Price Oscillator, Ease of Movement, Ulcer Index, Know Sure Thing, Volume-Price Trend, Simple Moving Average, Schaff Trend Cycle, Negative Volume Index, Exponential Moving Average, Relative Strength Index, Volume-Weighted Average Price, Weighted Moving Average, Stochastic RSI, Average True Range, Moving Average Convergence Divergence, Ultimate Oscillator, Money Flow Index, 및 Average Directional Index가 있습니다. 한국투자증권 MTS는 이들 중 37개 지표를 지원합니다.</content>\n",
            "<sub>Peer Analysis</sub>\n",
            "<content>Netflix와 유사한 사업을 하는 기업의 종가 데이터를 feature로 추가하고, PINS는 2019년 4월 22일 상장하여 상장 이전 결측값은 상장일 종가 2499$로 대체한다.</content>\n",
            "<sub>Remove multicollinearity</sub>\n",
            "<content>기본 지표(Open, Close, High, Low, SMA 등)는 유지하고, 주가 변화 관련 보조 지표(VMAP, BHB, BLB 등) 중 상관관계가 높은 지표는 제외합니다. 또한, FB, PINS, SPOT 등의 Peer 주식은 유지합니다.</content>\n",
            "<sub>Make derived variable for News Topics & Sentiment</sub>\n",
            "<content>내용 요약:\n",
            "- 주제: 라벨 인코딩, SMA(6OMA, 12OMA)\n",
            "- 감정 분석: 원-핫 인코딩, 5MM, 6OMM, 12OMM\n",
            "- 당일 뉴스는 당일 주가에 큰 영향을 미치지 않으므로 과거 뉴스의 영향력을 측정하기 위해 이동 평균 이동 모드를 추가함.</content>\n",
            "<sub>Dataset</sub>\n",
            "<content>- stockOnly-df: 1257행 38열\n",
            "- total-df: 1257행 59열</content>\n",
            "\n",
            "<main>MODELING</main>\n",
            "<sub>Time Series</sub>\n",
            "<content>시간에 따른 데이터 패턴 분석을 통해 미래 값을 예측하는 모델은, 연속된 데이터 수(W)를 입력받아 예측할 미래 데이터 길이(K)를 출력합니다. 이 모델의 고정된 윈도우 크기는 W+K입니다.</content>\n",
            "<sub>Modeling</sub>\n",
            "<content>1. 시퀀스 데이터 준비:\n",
            "   - 시퀀스 길이: 60, 예측 크기: 10\n",
            "   - 60개의 시퀀스 데이터와 10개의 예측 데이터를 사용\n",
            "\n",
            "2. 모델 정의:\n",
            "   - LSTM: 주가 예측에서 일반적으로 사용되며, 시퀀스 길이와 예측 크기를 다르게 설정하여 실험\n",
            "   - GRU: LSTM의 단순화된 버전으로 문제점을 극복\n",
            "   - Transformer: NLP에서 좋은 성능을 보이며, 주가 예측에서도 유의미한 결과를 검증하기 위해 선택\n",
            "\n",
            "3. 모델 비교:\n",
            "   - 예측 대상: 'CLOSE' vs 'ID-ROC'\n",
            "   - 데이터 포함 여부: 주가 데이터만 사용 vs 전체 데이터 사용\n",
            "   - 모델 비교: LSTM vs GRU vs Transformer</content>\n",
            "\n",
            "<main>CONCLUSIONS AND LIMITATIONS</main>\n",
            "<sub>Evaluation</sub>\n",
            "<content>- 예측 평가 기준: MSE 대신 RMSE 사용.\n",
            "- 예측 타겟 변수: Close 종가와 1dLROC 일일 등락 중 선택.\n",
            "- 뉴스 데이터의 유의미성: StockOnly-df와 total Df 비교.\n",
            "- 예측 모델 비교: LSTM, GRU, Transformer 중 가장 효과적인 모델 선택.</content>\n",
            "<sub>Select target variable</sub>\n",
            "<content>다음은 요약된 내용입니다:\n",
            "\n",
            "- 두 가지 데이터셋(stockOnly-df, total-df)과 설정(LSTM 모델, 시퀀스 크기 60, 배치 크기 8, 모델 크기 64)을 사용하여 주가 예측을 진행.\n",
            "- Close 값을 직접 예측하는 것보다 ROC를 이용한 예측이 추세를 더 잘 반영함.\n",
            "- 시계열 예측의 신뢰성을 높이기 위해 ROC를 예측 타겟으로 확정함.</content>\n",
            "<sub>Model Result</sub>\n",
            "<content>LSTM, GRU, Transformer 모두 RMSE를 손실 함수로 사용함.</content>\n",
            "<sub>Compare each parameter</sub>\n",
            "<content>LSTM 모델의 평균 loss 값이 가장 작고, transformer 모델이 가장 큽니다. GRU 모델은 주식 데이터만 사용했을 때, LSTM과 transformer 모델은 뉴스 데이터를 포함했을 때 평균 loss 값이 더 작습니다. Sequence_size와 Batch-size가 작을수록 유의미한 결과를 보이며, Model Size에서는 LSTM과 Transformer는 64에서, GRU는 128에서 유의미한 결과를 보입니다.</content>\n",
            "<sub>Best parameter for each model</sub>\n",
            "<content>모델별 최적 파라미터 조합을 50번 반복하여 평균값을 기반으로 경향성과 오차율을 분석한 결과:\n",
            "\n",
            "- LSTM (stock-only 데이터셋): seq 30, batch 8, model 64, 평균 오차율 185%\n",
            "- GRU (total 데이터셋): seq 30, batch 8, model 128, 평균 오차율 166%\n",
            "- Transformer (total 데이터셋): seq 30, batch 8, model 64, 평균 오차율 162%</content>\n",
            "<sub>Limitations</sub>\n",
            "<content>금융 시장에서는 예측이 어려워 모델 성능을 평가하기 위해 일일이 예측 그래프를 확인해야 하며, 실험 결과를 비교하는데 시간이 많이 소요된다. 뉴스 Topic NLP로 감성분석과 토픽모델링을 시도했으나 시퀀스 길이 문제와 정확도 한계로 Ap를 사용했다. 일반적으로 5% 오차는 좋은 평가를 받지만, 주식 시장에서는 큰 손실 또는 이익을 초래할 수 있어 5% 이하의 오차라도 신중한 검토가 필요하다.</content>\n"
          ]
        }
      ],
      "source": [
        "def summarize_content(content):\n",
        "    if not content.strip():\n",
        "        return content\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    다음 내용을 요약해줘:\n",
        "\n",
        "    내용: {content}\n",
        "\n",
        "    위 내용을 간결하게 요약해줘.\n",
        "    \"\"\"\n",
        "\n",
        "    response = llm_4.invoke(prompt)\n",
        "    summary = response.content.strip()\n",
        "    return summary\n",
        "\n",
        "summarized_detailed_info = re.sub(\n",
        "    r'(<content>)(.*?)(</content>)',\n",
        "    lambda m: f\"{m.group(1)}{summarize_content(m.group(2))}{m.group(3)}\",\n",
        "    detailed_info,\n",
        "    flags=re.DOTALL\n",
        ")\n",
        "\n",
        "print(summarized_detailed_info)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
