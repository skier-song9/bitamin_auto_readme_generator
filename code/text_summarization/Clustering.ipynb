{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "048f32c2-a1d3-48e8-bb32-9c60e2d61fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "import requests\n",
    "from openai import OpenAI\n",
    "\n",
    "import pandas as pd\n",
    "import glob,os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "RANDOM_STATE = 142"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bce51905-8fde-42f0-8c3d-bdcc2eae970c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk-proj-9fgPXhZ8FagHuaZZVP8eT3BlbkFJEysN4rXsHIdoRIa3XuUC\n"
     ]
    }
   ],
   "source": [
    "with open(\"../assets/openai_api_key.json\", 'r') as f:\n",
    "    api_key = json.load(f)\n",
    "api_key = api_key['OPENAI_API_KEY']\n",
    "print(api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd0952a7-829c-49fd-84e3-86e0fbc2a22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "800b0cb1-9a3f-4db0-8c06-a9fff3ec6c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def text_by_pages(filepath):\n",
    "    ### 문서를 페이지별로 구분하여 list에 저장\n",
    "    with open(filepath,'r',encoding='utf-8') as f:\n",
    "        data = f.readlines()\n",
    "    text = []\n",
    "    page_text = []\n",
    "    page_pattern = re.compile('<p.\\d*>')\n",
    "    for d in data:\n",
    "        # d = d.replace('\\n', ' <lf> ') # lf = line feed\n",
    "        d = d.replace('\\n', ' \\n') \n",
    "        if page_pattern.match(d):\n",
    "            if len(page_text)>0:\n",
    "                text.append(' '.join(page_text))\n",
    "            page_text = [] # 페이지 텍스트 초기화\n",
    "        page_text.append(d)\n",
    "    text.append(''.join(page_text)) # 마지막에는 수동으로 추가\n",
    "    return text\n",
    "\n",
    "def get_chat_completion(msg, model='gpt-4o-mini',**kargs):\n",
    "    response = client.chat.completions.create(\n",
    "        model = model,\n",
    "        messages = msg\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def erase_page_tag(plist):\n",
    "    page_pattern = re.compile('<p.\\d*>')\n",
    "    plist = [page_pattern.sub('',x) for x in plist]\n",
    "    return plist\n",
    "\n",
    "def extract_text_between_tag(text, tag):\n",
    "    # Create a regex pattern for the specified tag\n",
    "    pattern = f'<{tag}>(.*?)</{tag}>'\n",
    "    # Use re.findall to extract all occurrences between the specified tags\n",
    "    matches = re.findall(pattern, text, re.DOTALL)\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23276f3b-ebbf-449e-a6a1-287101310a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    }
   ],
   "source": [
    "sample1 = text_by_pages('./sample1.txt')\n",
    "print(len(sample1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6835c0f2-6117-4c7e-b449-c49b2d481444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<subject>독자와 웹툰 간 로그데이터를 활용한 웹툰 추천 시스템</subject>\n",
      "<team>강나영, 김나현, 엄성원, 이철민</team>\n",
      "<index>프로젝트 소개, 데이터 수집 및 전처리, 모델 선택 및 학습, 웹툰 추천 시스템 구현, 결론 및 향후 과제</index>\n"
     ]
    }
   ],
   "source": [
    "messages=[\n",
    "    {\"role\": \"system\", \n",
    "     \"content\": \"\"\"triple quotes 사이에 있는 문서를 참조하여 아래 3가지 작업을 수행하여라. 문서는 pdf 파일을 텍스트로 변환한 것이다. 문서는 <lf> 태그로 구분된 passage들로 구성되어 있다. passage들은 pdf에서 서로 다른 textbox이다. 단, 반복적으로 등장하는 passage는 무의미한 textbox이므로 답변에 포함시키지 말아라.\n",
    "- 작업1: 문서의 \"주제\"에 해당하는 paasage를 선택하여라.\n",
    "- 작업2: 사람의 이름을 추출하여 쉼표(,)로 연결하여라.\n",
    "- 작업3: 문서의 목차(index)를 추출하여 쉼표(,)로 연결하여라.\n",
    "\n",
    "3가지 작업 내용에 대해 다음과 같은 형식에 맞춰 답변하여라. 만약 작업의 결과가 명확하지 않다면 해당 결과에는 None을 출력하여라.\n",
    "<subject>작업1의 결과</subject>\n",
    "<team>작업2의 결과</team>\n",
    "<index>작업3의 결과</index>\n",
    "     \"\"\"\n",
    "    },\n",
    "    {\"role\": \"user\", \n",
    "     \"content\": f'\"\"\"{\" \".join(sample1[:5]) + \" \".join(sample1[-3:])}\"\"\"'\n",
    "    }\n",
    "]\n",
    "answer1 = get_chat_completion(messages)\n",
    "print(answer1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fab9de77-ef6c-4ddc-a454-7325d5fb3a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<subject>웹툰 추천 시스템</subject>  \n",
      "<team>강나영, 김나현, 엄성원, 이철민</team>  \n",
      "<index>01 프로젝트 소개 프로젝트 배경 프로젝트 목표 02 데이터 수집 및 전처리 데이터 소스 설명 데이터 전처리 03 모델 선택 및 학습 모델 비교 최종모델 선정 04 웹툰 추천 시스템 구현 기존 사용자 신규 사용자 05 결론 및 향후 과제 프로젝트 요약 및 의의 한계점 및 향후 과제</index>\n"
     ]
    }
   ],
   "source": [
    "# 별루...\n",
    "# messages=[\n",
    "#     {\"role\": \"system\", \n",
    "#      \"content\": \"\"\"\n",
    "#      You will be provided with a pair of passages delimited with <lf> tags. Passages represent the content of the project. Answer each given questions in a specified formats.\n",
    "     \n",
    "#      Question 1 - What is the main subject of project? Answer in <subject> tag.\n",
    "#      Question 2 - List the names of the people who participated in the project in <team> tag.\n",
    "#      Question 3 - What is the table of contents of this project? Answer in <index> tag.\n",
    "\n",
    "#      Answer in Korean.\n",
    "#      \"\"\"\n",
    "#     },\n",
    "#     {\"role\": \"user\", \n",
    "#      \"content\": f'\"\"\"{\" \".join(erase_page_tag(sample1[:5]))}\"\"\"'\n",
    "#     }\n",
    "# ]\n",
    "# answer = get_chat_completion(messages)\n",
    "# print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9722176a-5284-4101-bf3f-a72bd3521ba5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20381b87-830a-4c0b-ba92-6b2210484b57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73243672-1659-4ecc-a94a-dc819b8d206e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    }
   ],
   "source": [
    "sample2 = text_by_pages('./sample2.txt')\n",
    "print(len(sample2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f5e22b2-cd08-40cf-b1ca-a2a03cb6849e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<subject>Netflix Stock Price Prediction with News Topic & Sentiment</subject>  \n",
      "<team>송규헌, 권도영, 이태경, 김서윤, 한진솔</team>  \n",
      "<index>INTRODUCTION, DATA PREPROCESSING, MODELING, CONCLUSIONS AND LIMITATION</index>\n"
     ]
    }
   ],
   "source": [
    "messages=[\n",
    "    {\"role\": \"system\", \n",
    "     \"content\": \"\"\"triple quotes 사이에 있는 문서를 참조하여 아래 3가지 작업을 수행하여라. 문서는 pdf 파일을 텍스트로 변환한 것이다. 문서는 <lf> 태그로 구분된 passage들로 구성되어 있다. passage들은 pdf에서 서로 다른 textbox이다.ㅍ단, 반복적으로 등장하는 passage는 무의미한 textbox이므로 답변에 포함시키지 말아라.\n",
    "- 작업1: 문서의 \"주제\"에 해당하는 paasage를 선택하여라.\n",
    "- 작업2: 사람의 이름을 추출하여 쉼표(,)로 연결하여라.\n",
    "- 작업3: 문서의 목차(index)를 추출하여 쉼표(,)로 연결하여라.\n",
    "\n",
    "3가지 작업 내용에 대해 다음과 같은 형식에 맞춰 답변하여라. 만약 작업의 결과가 명확하지 않다면 해당 결과에는 None을 출력하여라.\n",
    "<subject>작업1의 결과</subject>\n",
    "<team>작업2의 결과</team>\n",
    "<index>작업3의 결과</index>\n",
    "     \"\"\"\n",
    "    },\n",
    "    {\"role\": \"user\", \n",
    "     \"content\": f'\"\"\"{\" \".join(sample2[:5]) + \" \".join(sample2[-3:])}\"\"\"'\n",
    "    }\n",
    "]\n",
    "answer2 = get_chat_completion(messages)\n",
    "print(answer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e2859f-1ee1-4719-a4d5-b0e050277260",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f301bc50-ef0f-4a45-bbda-77a3dc9314f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "efeb32a7-c1eb-4bfc-988e-c13f8306fca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    }
   ],
   "source": [
    "sample3 = text_by_pages('./sample3.txt')\n",
    "print(len(sample3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37053a2d-ab30-49a7-8941-e42d15fef598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<subject>비타민 11기 겨울 컨퍼런스 LLM 기반 거짓말 탐지기</subject>\n",
      "<team>조민호, 박소연, 박준형, 박세준</team>\n",
      "<index>서비스 배경 및 기획, 모델 구축 과정, 결론 및 제언</index>\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "\t{\n",
    "\t\"role\" : \"system\",\n",
    "\t\"content\" : \"\"\"triple quotes 사이에 있는 문서를 참조하여 아래 3가지 작업을 수행하여라. 문서는 pdf 파일을 텍스트로 변환한 것이다. <p.숫자>는 문서의 페이지 번호를 의미한다. 문서는 <lf> 태그로 구분된 passage들로 구성되어 있다. passage들은 pdf에서 서로 다른 textbox이다. 단, 반복적으로 등장하는 passage는 무의미한 textbox이므로 답변에 포함시키지 말아라.\n",
    "- 작업1: 문서의 \"주제\"에 해당하는 paasage를 선택하여라.\n",
    "- 작업2: 사람의 이름을 추출하여 쉼표(,)로 연결하여라.\n",
    "- 작업3: 문서의 목차(table of contents)를 추출하여 쉼표(,)로 연결하여라.\n",
    "\n",
    "3가지 작업 내용에 대해 다음과 같은 형식에 맞춰 답변하여라. 만약 작업의 결과가 명확하지 않다면 해당 결과에는 None을 출력하여라.\n",
    "<subject>작업1의 결과</subject>\n",
    "<team>작업2의 결과</team>\n",
    "<index>작업3의 결과</index>\n",
    "     \"\"\"\n",
    "   },\n",
    "\t{\n",
    "\t\"role\" : \"user\",\n",
    "\t\"content\" : f'\"\"\"{\" \".join(sample3[:5]) + \" \".join(sample3[-3:])}\"\"\"'\n",
    "\t}\n",
    "]\n",
    "answer3 = get_chat_completion(messages)\n",
    "print(answer3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd45207b-826d-404e-967b-7347a23b1b98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f6cf384-b590-420e-a3fa-cd862340c05a",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "1. Embedding Model, Clustering Algorithm 별로 군집화를 진행\n",
    "2. SS, CHI 지표를 측정하여 가장 pdf별로 가장 좋은 embedding model, clustering algo 조합 결과를 채택\n",
    "3. 직접 매긴 target cluster와 비교 -> ARI, HS 지표"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d0d1ca9-3cf6-4602-aed8-61103c14aa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "def pca_best_component(X):\n",
    "    '''\n",
    "    최적의 PCA component값을 찾는 함수\n",
    "    '''\n",
    "    pca_optimize = PCA()\n",
    "    pca_optimize.fit(X)\n",
    "    \n",
    "    # 누적 설명된 분산 비율 계산\n",
    "    cumulative_variance = np.cumsum(pca_optimize.explained_variance_ratio_)\n",
    "    \n",
    "    # 99% 이상 설명력을 갖는 주성분 개수 계산\n",
    "    n_components = np.argmax(cumulative_variance >= 0.99) + 1\n",
    "    \n",
    "    # 설명된 분산 비율 시각화\n",
    "    # plt.figure(figsize=(10, 6))\n",
    "    # plt.plot(cumulative_variance, marker='o', linestyle='--', color='b')\n",
    "    # plt.xlabel('Number of Components')\n",
    "    # plt.ylabel('Cumulative Explained Variance')\n",
    "    # plt.title('Cumulative Explained Variance by Number of Components')\n",
    "    # plt.axvline(x=n_components, color='r', linestyle=':', label=f'{n_components} components (95% explained variance)')\n",
    "    # plt.legend()\n",
    "    # plt.grid()\n",
    "    # plt.show()\n",
    "    # print(f\"99% 이상의 설명력을 갖기 위해 {n_components}개의 주성분으로 나누어야 합니다.\")\n",
    "\n",
    "    return n_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b63fd91b-221a-4629-a65d-f30164a604b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install kneed\n",
    "from sklearn.cluster import KMeans\n",
    "from kneed import KneeLocator\n",
    "\n",
    "# 클러스터 개수 변화에 따른 SSE 확인, Elbow Point 찾기\n",
    "def SSE_graph(K, data):\n",
    "    SSE = []\n",
    "    k = 1\n",
    "    while 1 <= k <= K:\n",
    "        k_means = KMeans(n_clusters = k)     # 클러스터 개수가 k개인 모델 생성\n",
    "        k_means.fit(data)\n",
    "        SSE.append(k_means.inertia_)     # inertia : sum of squared distances of samples to their closest cluster center\n",
    "        k += 1\n",
    "     \n",
    "    plt.plot(range(1, K+1), SSE, 'o')     # K값에 따른 SSE 표시\n",
    "    plt.plot(range(1, K+1), SSE, '--')     # SSE값을 연결하는 직선 그리기\n",
    "    plt.xlabel('K')\n",
    "    plt.ylabel('SSE')\n",
    "    kn = KneeLocator(range(1, K+1), SSE, curve = 'convex', direction = 'decreasing')    \n",
    "    return SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e8e4e3b0-8767-418b-b861-c30bdc54d318",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 여러개의 클러스터링 갯수를 List로 입력 받아 각각의 실루엣 계수를 면적으로 \n",
    "### 시각화한 함수 작성\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import math\n",
    "\n",
    "def visualize_silhouette(max_cluster, X_features):     \n",
    "    '''\n",
    "    K-means, Spectral clustering에서 최적의 K값을 찾는 함수\n",
    "    '''\n",
    "    # cluster의 최솟값은 3으로 고정하고 clusterlist를 만든다.\n",
    "    min_cluster = 4\n",
    "    cluster_lists = [x for x in range(min_cluster,max_cluster)]\n",
    "    \n",
    "    # 입력값으로 클러스터링 갯수들을 리스트로 받아서, 각 갯수별로 클러스터링을 적용하고 실루엣 개수를 구함\n",
    "    n_cols = len(cluster_lists)\n",
    "    \n",
    "    # plt.subplots()으로 리스트에 기재된 클러스터링 수만큼의 sub figures를 가지는 axs 생성 \n",
    "    # fig, axs = plt.subplots(figsize=(4*n_cols, 4), nrows=1, ncols=n_cols)\n",
    "\n",
    "    results = []\n",
    "    # 리스트에 기재된 클러스터링 갯수들을 차례로 iteration 수행하면서 실루엣 개수 시각화\n",
    "    for ind, n_cluster in enumerate(cluster_lists):\n",
    "        \n",
    "        # KMeans 클러스터링 수행하고, 실루엣 스코어와 개별 데이터의 실루엣 값 계산. \n",
    "        clusterer = KMeans(n_clusters = n_cluster, max_iter=500, random_state=0)\n",
    "        cluster_labels = clusterer.fit_predict(X_features)\n",
    "        \n",
    "        sil_avg = silhouette_score(X_features, cluster_labels)\n",
    "        sil_values = silhouette_samples(X_features, cluster_labels)\n",
    "        \n",
    "        # y_lower = 10\n",
    "        # axs[ind].set_title('Number of Cluster : '+ str(n_cluster)+'\\n' \\\n",
    "        #                   'Silhouette Score :' + str(round(sil_avg,3)) )\n",
    "        # axs[ind].set_xlabel(\"The silhouette coefficient values\")\n",
    "        # axs[ind].set_ylabel(\"Cluster label\")\n",
    "        # axs[ind].set_xlim([-0.1, 1])\n",
    "        # axs[ind].set_ylim([0, len(X_features) + (n_cluster + 1) * 10])\n",
    "        # axs[ind].set_yticks([])  # Clear the yaxis labels / ticks\n",
    "        # axs[ind].set_xticks([0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "        \n",
    "        # 클러스터링 갯수별로 fill_betweenx( )형태의 막대 그래프 표현. \n",
    "        # for i in range(n_cluster):\n",
    "        #     ith_cluster_sil_values = sil_values[cluster_labels==i]\n",
    "        #     ith_cluster_sil_values.sort()\n",
    "            \n",
    "        #     size_cluster_i = ith_cluster_sil_values.shape[0]\n",
    "        #     y_upper = y_lower + size_cluster_i\n",
    "            \n",
    "        #     color = cm.nipy_spectral(float(i) / n_cluster)\n",
    "        #     axs[ind].fill_betweenx(np.arange(y_lower, y_upper), 0, ith_cluster_sil_values, \\\n",
    "        #                         facecolor=color, edgecolor=color, alpha=0.7)\n",
    "        #     axs[ind].text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "        #     y_lower = y_upper + 10\n",
    "            \n",
    "            \n",
    "        # axs[ind].axvline(x=sil_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "        results.append([sil_avg, np.var([x if x>=0 else 0 for x in sil_values])])\n",
    "\n",
    "    ### 결과를 토대로 최적의 K 값을 도출\n",
    "    # 1. 실루엣 계수의 평균과 분산에 대해 MinMax 정규화\n",
    "    results_df = pd.DataFrame(data=results,columns=['avg','var']) \n",
    "    mms = MinMaxScaler()\n",
    "    results_df[['avg_norm', 'var_norm']] = mms.fit_transform(results_df[['avg', 'var']])\n",
    "    # 2. 표준화된 var을 1에서 빼서 \"분산은 작은 값이 좋음\"을 반영\n",
    "    results_df['var_norm'] = 1 - results_df['var_norm']\n",
    "    # 3. 가중 평균 계산 (평균에 대한 가중치: 0.65, 분산에 대한 가중치: 0.35 -> 가중치에 대한 근거는 경험적 판단.)\n",
    "    results_df['score'] = results_df['avg_norm'] * 0.65 + results_df['var_norm'] * 0.35    \n",
    "    sorted_results = results_df.sort_values('score',ascending=False)\n",
    "    optimal_k = sorted_results.index[0]+min_cluster\n",
    "    return optimal_k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1f1269-973e-4dab-8a4f-7116a9f9362f",
   "metadata": {},
   "source": [
    "### Embedding\n",
    "- BERT 기반의 LaBSE 모델을 사용하여 문장 임베딩 (max sequence length = 256)\n",
    "- ConvBERT 모델 : text feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "79795818-692a-4f44-975b-4ad071417747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sentence-transformers\n",
    "# !pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "904017d3-a21b-497a-bcb4-1eb4f59b8a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Sentence Transformer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "se_model = SentenceTransformer('sentence-transformers/LaBSE') # BERT 기반 문장 임베딩 모델\n",
    "\n",
    "# 2. ConvBERT \n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "convbert_tokenizer = AutoTokenizer.from_pretrained(\"YituTech/conv-bert-base\")\n",
    "convbert_model = AutoModel.from_pretrained(\"YituTech/conv-bert-base\")\n",
    "\n",
    "# 3. Canine\n",
    "from transformers import CanineTokenizer, CanineModel\n",
    "canine_tokenizer = CanineTokenizer.from_pretrained('google/canine-c')\n",
    "canine_model = CanineModel.from_pretrained('google/canine-c')\n",
    "\n",
    "# 4. OpenAI text-embedding-ada-002\n",
    "# !pip install -U tiktoken\n",
    "import tiktoken\n",
    "openai_model = tiktoken.encoding_for_model(\"text-embedding-ada-002\")\n",
    "# from transformers import GPT2Tokenizer\n",
    "# tokenizer = GPT2Tokenizer.from_pretrained('Xenova/text-embedding-ada-002')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "594507c0-1b49-415f-a998-a2bb6968ed2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Encoding 'cl100k_base'>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "474d26a2-fb62-4bad-91bd-8008f47427d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15339, 856, 836, 374, 7043, 0]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai_model.encode('hello my name is Paul!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e24bd07f-2264-48ca-87bc-80912e3acd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {\n",
    "    'sentence':[se_model],\n",
    "    'token':[(convbert_tokenizer,convbert_model),(canine_tokenizer,canine_model)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "df3b116f-4de7-43ad-9d9c-1480644f65eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import SpectralClustering,KMeans\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score\n",
    "import torch\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import gc\n",
    "\n",
    "def clustering(text, n_clusters, model_dict, random_state):\n",
    "    '''\n",
    "    text : pdf 문서를 page별로 구분한 리스트 전달.\n",
    "    n_clusters : 클러스터의 개수를 지정 -> extract_text_between_tag(text,'index')로 추출한 인덱스의 개수 + 2\n",
    "\n",
    "    return\n",
    "        - total_metrics : 모델별, 클러스터링 알고리즘별 클러스터링 결과를 SS, CHI로 평가지표로 측정한 결과에 대한 데이터프레임\n",
    "        - total_dict : model_name을 key값으로 text, cluster label, embedding 컬럼으로 하는 데이터프레임을 value로 갖는 딕셔너리\n",
    "    '''\n",
    "    total_metrics = pd.DataFrame(columns=['model','kmeans_ss','spectral_ss','kmeans_chi','spectral_chi'])\n",
    "    total_dict = {}\n",
    "    max_cluster = len(text)-1\n",
    "    # sentence 단위로 임베딩하는 모델의 경우\n",
    "    for model in model_dict['sentence']:\n",
    "        model_name = str(model.__class__).split('.')[-1][:-2]\n",
    "        text_embeddings = model.encode(erase_page_tag(text))\n",
    "        # 최적의 k값 찾기 [x] >> pdf의 인덱스 개수에 맞춰 n_clusters를 설정\n",
    "        # optimal_k = visualize_silhouette(max_cluster=max_cluster,X_features=text_embeddings)\n",
    "        # kmeans와 spectral clustering 진행\n",
    "        kmeans = KMeans(n_clusters=n_clusters, \n",
    "                init='k-means++', # centroid들을 서로 최대한 멀리 배치하는 initialisation 방식\n",
    "                max_iter = 500,\n",
    "                random_state = random_state)\n",
    "        spectral = SpectralClustering(n_clusters=n_clusters, affinity='nearest_neighbors',\n",
    "                             random_state=random_state)\n",
    "        kmeans.fit(text_embeddings)\n",
    "        spectral.fit(text_embeddings)\n",
    "        # 평가지표 계산\n",
    "        new_row = pd.DataFrame(data=[[\n",
    "            model_name, # model name\n",
    "            silhouette_score(text_embeddings, kmeans.labels_), # kmeans ss\n",
    "            silhouette_score(text_embeddings, spectral.labels_), # spectral ss\n",
    "            calinski_harabasz_score(text_embeddings, kmeans.labels_), # kmeans chi\n",
    "            calinski_harabasz_score(text_embeddings, spectral.labels_) # spectral chi\n",
    "        ]], columns = total_metrics.columns)\n",
    "\n",
    "        # Save results\n",
    "        total_metrics = pd.concat([total_metrics, new_row],axis=0,ignore_index=True)\n",
    "        temp_df = pd.DataFrame(data=[\n",
    "            text, kmeans.labels_, spectral.labels_\n",
    "        ]).transpose()\n",
    "        temp_df.columns = ['text','kmeans','spectral']\n",
    "        total_dict[model_name] = pd.concat([\n",
    "            temp_df,pd.DataFrame(text_embeddings)\n",
    "        ],axis=1)\n",
    "\n",
    "        # garbage collection > 별 의미 없는 듯\n",
    "        # gc.collect()\n",
    "\n",
    "    # token 단위로 임베딩하는 모델의 경우\n",
    "    for tokenizer, model in model_dict['token']:\n",
    "        model_name = str(model.__class__).split('.')[-1][:-2]\n",
    "        if model_name == 'CanineModel':\n",
    "            token = tokenizer(erase_page_tag(text), padding='longest', truncation=True, return_tensors='pt')\n",
    "        else:\n",
    "            token = tokenizer(erase_page_tag(text), padding='longest',return_tensors='pt')\n",
    "        text_embeddings = model(**token).last_hidden_state.detach()\n",
    "        flattened = text_embeddings.view(text_embeddings.shape[0],-1)\n",
    "        ### 차원 축소 : PCA + t-SNE\n",
    "        # PCA n_component 구하기\n",
    "        optimal_component = pca_best_component(flattened)\n",
    "        # PCA\n",
    "        text_embeddings = PCA(n_components=optimal_component, random_state=random_state).fit_transform(flattened)\n",
    "        # t-SNE (3차원으로 축소하는 것으로 고정)\n",
    "        # perplexity는 일반적으로 데이터 개수의 3분의 1 이하\n",
    "        general_perplexity = int(text_embeddings.shape[0]/3)\n",
    "        # 최솟값은 5, 최댓값은 50으로 제한\n",
    "        if general_perplexity<5:\n",
    "            general_perplexity = 5\n",
    "        elif general_perplexity>50:\n",
    "            general_perplexity=50\n",
    "        text_embeddings = TSNE(n_components=3, perplexity=general_perplexity,\n",
    "                               random_state=random_state).fit_transform(text_embeddings)\n",
    "\n",
    "        # 최적의 k값 찾기 [x] >> pdf의 인덱스 개수에 맞춰 n_clusters를 설정\n",
    "        # optimal_k = visualize_silhouette(max_cluster=max_cluster,X_features=text_embeddings)\n",
    "        # kmeans와 spectral clustering 진행\n",
    "        kmeans = KMeans(n_clusters=n_clusters, \n",
    "                init='k-means++', # centroid들을 서로 최대한 멀리 배치하는 initialisation 방식\n",
    "                max_iter = 500,\n",
    "                random_state = random_state)\n",
    "        spectral = SpectralClustering(n_clusters=n_clusters, affinity='nearest_neighbors',\n",
    "                             random_state=random_state)\n",
    "        kmeans.fit(text_embeddings)\n",
    "        spectral.fit(text_embeddings)\n",
    "        # 평가지표 계산\n",
    "        new_row = pd.DataFrame(data=[[\n",
    "            model_name, # model name\n",
    "            silhouette_score(text_embeddings, kmeans.labels_), # kmeans ss\n",
    "            silhouette_score(text_embeddings, spectral.labels_), # spectral ss\n",
    "            calinski_harabasz_score(text_embeddings, kmeans.labels_), # kmeans chi\n",
    "            calinski_harabasz_score(text_embeddings, spectral.labels_) # spectral chi\n",
    "        ]], columns = total_metrics.columns)\n",
    "\n",
    "        # Save results\n",
    "        total_metrics = pd.concat([total_metrics, new_row],axis=0,ignore_index=True)\n",
    "        temp_df = pd.DataFrame(data=[\n",
    "            text, kmeans.labels_, spectral.labels_\n",
    "        ]).transpose()\n",
    "        temp_df.columns = ['text','kmeans','spectral']\n",
    "        total_dict[model_name] = pd.concat([\n",
    "            temp_df,pd.DataFrame(text_embeddings)\n",
    "        ],axis=1)\n",
    "\n",
    "        # garbage collection\n",
    "        # gc.collect()\n",
    "\n",
    "    return total_metrics, total_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "78f6d6f2-bbd9-425a-86b5-0adc91a2e0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_model_n_algo(metrics_df):\n",
    "    \"\"\"\n",
    "    metrics_df : clustering함수 결과로 얻은 total_metrics\n",
    "\n",
    "    return : total_metrics에서 가장 성능이 좋은 model과 클러스터링 알고리즘을 반환 \n",
    "    -> total_dict에서 해당 모델 이름과 클러스터링 알고리즘 이름으로 클러스터 결과를 찾을 수 있음.\n",
    "    \"\"\"\n",
    "    metrics_df['kmeans']=metrics_df['kmeans_ss']+metrics_df['kmeans_chi']\n",
    "    metrics_df['spectral']=metrics_df['spectral_ss']+metrics_df['spectral_chi']\n",
    "    \n",
    "    max_value = metrics_df[['spectral','kmeans']].max().max()\n",
    "    # 최대값을 가진 행과 열 찾기\n",
    "    max_value_row_col = metrics_df[['spectral', 'kmeans']].apply(lambda x: x == max_value).stack()\n",
    "    max_value_row_col = max_value_row_col[max_value_row_col].index[0]\n",
    "    model_name = metrics_df.loc[max_value_row_col[0],'model']\n",
    "    clustering_algo = max_value_row_col[1]\n",
    "    return model_name, clustering_algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eb6a9b66-53b0-4896-9a3f-7ff7a3d9f709",
   "metadata": {},
   "outputs": [],
   "source": [
    "def renew_cluster_byorder(dfs, best):\n",
    "    '''\n",
    "    dfs : clustering 함수 결과로 얻은 total_dict\n",
    "    best = (best_model, best_algo) 튜플\n",
    "        - best_model : best_model_n_algo 결과로 얻은 model_name\n",
    "        - best_algo : best_model_n_algo 결과로 얻은 clustering_algo\n",
    "\n",
    "    return df : 순서가 엉켜있는 cluster label을 재정렬한 결과를 반환\n",
    "    '''\n",
    "    best_model, best_algo = best\n",
    "    df = dfs[best_model][['text',best_algo]]\n",
    "    cnum = len(df[best_algo].unique())\n",
    "    checklist = []\n",
    "    for c in df[best_algo]:\n",
    "        if c not in checklist:\n",
    "            checklist.append(c)\n",
    "        if len(checklist) == cnum:\n",
    "            break\n",
    "    renew_c = list(range(cnum))\n",
    "    df['new_cluster'] = df[best_algo].apply(lambda x:renew_c[checklist.index(x)])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b756b6ed-cc56-4d69-af6a-0cf1f55a6c6e",
   "metadata": {},
   "source": [
    "### sample별 clustering 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5cc928dc-0d5c-4c0a-95e3-d41dd494c0ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.56 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "### 첫 5페이지에서 요약한 <index> 정보를 통해 n_clusters 설정\n",
    "s1_nclusters = len(extract_text_between_tag(answer1,'index')[0].split(',')) + 2\n",
    "s2_nclusters = len(extract_text_between_tag(answer2,'index')[0].split(',')) + 2\n",
    "s3_nclusters = len(extract_text_between_tag(answer3,'index')[0].split(',')) + 2\n",
    "\n",
    "s1_metrics, s1_dfs = clustering(text=sample1,\n",
    "                       n_clusters=s1_nclusters,\n",
    "                       model_dict=model_dict,\n",
    "                       random_state = RANDOM_STATE)\n",
    "s2_metrics, s2_dfs = clustering(text=sample2,\n",
    "                       n_clusters=s2_nclusters, \n",
    "                       model_dict=model_dict,\n",
    "                       random_state = RANDOM_STATE)\n",
    "s3_metrics, s3_dfs = clustering(text=sample3,\n",
    "                       n_clusters=s3_nclusters, \n",
    "                       model_dict=model_dict,\n",
    "                       random_state = RANDOM_STATE)\n",
    "print(f\"{time.time()-start_time:0.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "101f929e-9c4d-4f33-8a07-1b8df1f4c399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>kmeans_ss</th>\n",
       "      <th>spectral_ss</th>\n",
       "      <th>kmeans_chi</th>\n",
       "      <th>spectral_chi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SentenceTransformer</td>\n",
       "      <td>0.198973</td>\n",
       "      <td>0.156322</td>\n",
       "      <td>4.095193</td>\n",
       "      <td>3.260520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ConvBertModel</td>\n",
       "      <td>0.213544</td>\n",
       "      <td>0.042948</td>\n",
       "      <td>9.257685</td>\n",
       "      <td>4.993456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CanineModel</td>\n",
       "      <td>0.137470</td>\n",
       "      <td>-0.019971</td>\n",
       "      <td>12.495776</td>\n",
       "      <td>3.306574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  kmeans_ss  spectral_ss  kmeans_chi  spectral_chi\n",
       "0  SentenceTransformer   0.198973     0.156322    4.095193      3.260520\n",
       "1        ConvBertModel   0.213544     0.042948    9.257685      4.993456\n",
       "2          CanineModel   0.137470    -0.019971   12.495776      3.306574"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b0d3123e-3751-41e9-881b-6c92e76df3a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>kmeans_ss</th>\n",
       "      <th>spectral_ss</th>\n",
       "      <th>kmeans_chi</th>\n",
       "      <th>spectral_chi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SentenceTransformer</td>\n",
       "      <td>0.097473</td>\n",
       "      <td>0.105743</td>\n",
       "      <td>3.855598</td>\n",
       "      <td>4.021662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ConvBertModel</td>\n",
       "      <td>0.210228</td>\n",
       "      <td>0.193859</td>\n",
       "      <td>16.267961</td>\n",
       "      <td>15.038704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CanineModel</td>\n",
       "      <td>0.236595</td>\n",
       "      <td>0.238578</td>\n",
       "      <td>15.994352</td>\n",
       "      <td>15.610449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  kmeans_ss  spectral_ss  kmeans_chi  spectral_chi\n",
       "0  SentenceTransformer   0.097473     0.105743    3.855598      4.021662\n",
       "1        ConvBertModel   0.210228     0.193859   16.267961     15.038704\n",
       "2          CanineModel   0.236595     0.238578   15.994352     15.610449"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8f6cd31d-d14d-45ee-957f-ff241c1e8c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>kmeans_ss</th>\n",
       "      <th>spectral_ss</th>\n",
       "      <th>kmeans_chi</th>\n",
       "      <th>spectral_chi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SentenceTransformer</td>\n",
       "      <td>0.116498</td>\n",
       "      <td>0.094784</td>\n",
       "      <td>3.448194</td>\n",
       "      <td>3.337877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ConvBertModel</td>\n",
       "      <td>0.304815</td>\n",
       "      <td>0.284957</td>\n",
       "      <td>16.971637</td>\n",
       "      <td>17.315836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CanineModel</td>\n",
       "      <td>0.215659</td>\n",
       "      <td>0.224702</td>\n",
       "      <td>11.005822</td>\n",
       "      <td>11.449792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  kmeans_ss  spectral_ss  kmeans_chi  spectral_chi\n",
       "0  SentenceTransformer   0.116498     0.094784    3.448194      3.337877\n",
       "1        ConvBertModel   0.304815     0.284957   16.971637     17.315836\n",
       "2          CanineModel   0.215659     0.224702   11.005822     11.449792"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9a69fa16-df5e-4e8f-a1c5-060667e1b2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample1 : ('CanineModel', 'kmeans')\n",
      "sample2 : ('ConvBertModel', 'kmeans')\n",
      "sample3 : ('ConvBertModel', 'spectral')\n"
     ]
    }
   ],
   "source": [
    "print(f\"sample1 :\",best_model_n_algo(s1_metrics))\n",
    "print(f\"sample2 :\",best_model_n_algo(s2_metrics))\n",
    "print(f\"sample3 :\",best_model_n_algo(s3_metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2fc4a669-55d1-470d-8749-c10dd31e87c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 6 5\n"
     ]
    }
   ],
   "source": [
    "print(s1_nclusters,s2_nclusters,s3_nclusters)\n",
    "s1_renew = renew_cluster_byorder(dfs=s1_dfs, best=best_model_n_algo(metrics_df=s1_metrics))\n",
    "s2_renew = renew_cluster_byorder(dfs=s2_dfs, best=best_model_n_algo(metrics_df=s2_metrics))\n",
    "s3_renew = renew_cluster_byorder(dfs=s3_dfs, best=best_model_n_algo(metrics_df=s3_metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "08ec834a-e91a-484a-aff9-476dc44df4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 내가 직접 매긴 정답 clustering\n",
    "s1_renew['target'] = [0,0,1,2,2,2,3,3,3,3,3,3,3,3,3,3,3,4,4,5,5,6]\n",
    "s2_renew['target'] = [0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,4,4,4,4,5]\n",
    "s3_renew['target'] = [0,0,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,3,3,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5e91d346-e4fb-4c7e-8298-e10629e77d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08190772420943494 0.5591107510399288\n",
      "-0.019364092756394932 0.2142926030770089\n",
      "0.002308940610126665 0.22930542090012493\n"
     ]
    }
   ],
   "source": [
    "# ARI, HS\n",
    "from sklearn.metrics import adjusted_rand_score, homogeneity_score\n",
    "s1_air = adjusted_rand_score(s1_renew['target'], s1_renew['new_cluster'])\n",
    "s1_hs = homogeneity_score(s1_renew['target'], s1_renew['new_cluster'])\n",
    "print(s1_air, s1_hs)\n",
    "\n",
    "s2_air = adjusted_rand_score(s2_renew['target'], s2_renew['new_cluster'])\n",
    "s2_hs = homogeneity_score(s2_renew['target'], s2_renew['new_cluster'])\n",
    "print(s2_air, s2_hs)\n",
    "\n",
    "s3_air = adjusted_rand_score(s3_renew['target'], s3_renew['new_cluster'])\n",
    "s3_hs = homogeneity_score(s3_renew['target'], s3_renew['new_cluster'])\n",
    "print(s3_air, s3_hs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "655147d5-3945-4eb1-87ed-8f426d3d8b8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>kmeans</th>\n",
       "      <th>new_cluster</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;p.1&gt; \\n BITAmin \\n 24-1R 학기 프로젝트 \\n 독자와 웹툰 간 ...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;p.2&gt; \\n BITAmin \\n TABLE OF CONTENTS \\n 목차 소개...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;p.3&gt; \\n 01 프로젝트 소개 \\n 프로젝트 배경  \\n 정제된 '대량의 데이...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;p.4&gt; \\n 02 데이터 수집 및 전처리 \\n BITAmin \\n 데이터 소스 ...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;p.5&gt; \\n 02 데이터 수집 및 전처리 \\n BITAmin \\n 데이터 전처리...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>&lt;p.6&gt; \\n 02 데이터 수집 및 전처리 \\n BITAmin \\n 데이터 전처리...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&lt;p.7&gt; \\n 03 모델 선택 및 학습 - CF \\n BITAmin \\n CF(C...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>&lt;p.8&gt; \\n 03 모델 선택 및 학습 - CF \\n BITAmin \\n CF(C...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>&lt;p.9&gt; \\n 03 모델 선택 및 학습 - NCF \\n BITAmin \\n NCF...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>&lt;p.10&gt; \\n 03 모델 선택 및 학습 - NCF \\n BITAmin \\n NC...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>&lt;p.11&gt; \\n 03 모델 선택 및 학습 - SVD \\n BITAmin \\n SV...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>&lt;p.12&gt; \\n 03 모델 선택 및 학습 - SVD \\n BITAmin \\n SV...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>&lt;p.13&gt; \\n 03 모델 선택 및 학습 - SVD \\n BITAmin \\n SV...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>&lt;p.14&gt; \\n 03 모델 선택 및 학습 - ALS \\n BITAmin \\n AL...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>&lt;p.15&gt;  \\n 03  최종 모델 선정 \\n BITAmin \\n ALS(Alte...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>&lt;p.16&gt;  \\n 03  최종 모델 선정 \\n BITAmin \\n ALS(Alte...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>&lt;p.17&gt;  \\n 03  최종 모델 선정 \\n BITAmin \\n ALS(Alte...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>&lt;p.18&gt;  \\n 04 웹툰 추천 시스템 구현 - 기존 사용자  \\n BITAmi...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>&lt;p.19&gt;  \\n 04 웹툰 추천 시스템 구현 - 신규 사용자  \\n BITAmi...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>&lt;p.20&gt; \\n 05 결론 및 향후 과제  \\n BITAmin \\n 프로젝트 요약...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>&lt;p.21&gt; \\n 05 결론 및 향후 과제  \\n BITAmin \\n 한계점 \\n ...</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>&lt;p.22&gt; \\nBITAmin \\n24-1R 학기 프로젝트  \\n감사합니다 \\nRe...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text kmeans  new_cluster  \\\n",
       "0   <p.1> \\n BITAmin \\n 24-1R 학기 프로젝트 \\n 독자와 웹툰 간 ...      3            0   \n",
       "1   <p.2> \\n BITAmin \\n TABLE OF CONTENTS \\n 목차 소개...      6            1   \n",
       "2   <p.3> \\n 01 프로젝트 소개 \\n 프로젝트 배경  \\n 정제된 '대량의 데이...      4            2   \n",
       "3   <p.4> \\n 02 데이터 수집 및 전처리 \\n BITAmin \\n 데이터 소스 ...      4            2   \n",
       "4   <p.5> \\n 02 데이터 수집 및 전처리 \\n BITAmin \\n 데이터 전처리...      4            2   \n",
       "5   <p.6> \\n 02 데이터 수집 및 전처리 \\n BITAmin \\n 데이터 전처리...      1            3   \n",
       "6   <p.7> \\n 03 모델 선택 및 학습 - CF \\n BITAmin \\n CF(C...      6            1   \n",
       "7   <p.8> \\n 03 모델 선택 및 학습 - CF \\n BITAmin \\n CF(C...      5            4   \n",
       "8   <p.9> \\n 03 모델 선택 및 학습 - NCF \\n BITAmin \\n NCF...      6            1   \n",
       "9   <p.10> \\n 03 모델 선택 및 학습 - NCF \\n BITAmin \\n NC...      1            3   \n",
       "10  <p.11> \\n 03 모델 선택 및 학습 - SVD \\n BITAmin \\n SV...      3            0   \n",
       "11  <p.12> \\n 03 모델 선택 및 학습 - SVD \\n BITAmin \\n SV...      5            4   \n",
       "12  <p.13> \\n 03 모델 선택 및 학습 - SVD \\n BITAmin \\n SV...      5            4   \n",
       "13  <p.14> \\n 03 모델 선택 및 학습 - ALS \\n BITAmin \\n AL...      4            2   \n",
       "14  <p.15>  \\n 03  최종 모델 선정 \\n BITAmin \\n ALS(Alte...      1            3   \n",
       "15  <p.16>  \\n 03  최종 모델 선정 \\n BITAmin \\n ALS(Alte...      1            3   \n",
       "16  <p.17>  \\n 03  최종 모델 선정 \\n BITAmin \\n ALS(Alte...      6            1   \n",
       "17  <p.18>  \\n 04 웹툰 추천 시스템 구현 - 기존 사용자  \\n BITAmi...      3            0   \n",
       "18  <p.19>  \\n 04 웹툰 추천 시스템 구현 - 신규 사용자  \\n BITAmi...      3            0   \n",
       "19  <p.20> \\n 05 결론 및 향후 과제  \\n BITAmin \\n 프로젝트 요약...      0            5   \n",
       "20  <p.21> \\n 05 결론 및 향후 과제  \\n BITAmin \\n 한계점 \\n ...      2            6   \n",
       "21  <p.22> \\nBITAmin \\n24-1R 학기 프로젝트  \\n감사합니다 \\nRe...      5            4   \n",
       "\n",
       "    target  \n",
       "0        0  \n",
       "1        0  \n",
       "2        1  \n",
       "3        2  \n",
       "4        2  \n",
       "5        2  \n",
       "6        3  \n",
       "7        3  \n",
       "8        3  \n",
       "9        3  \n",
       "10       3  \n",
       "11       3  \n",
       "12       3  \n",
       "13       3  \n",
       "14       3  \n",
       "15       3  \n",
       "16       3  \n",
       "17       4  \n",
       "18       4  \n",
       "19       5  \n",
       "20       5  \n",
       "21       6  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1_renew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "778e77f8-15a3-4159-a82b-ce90c1c85d43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>kmeans</th>\n",
       "      <th>new_cluster</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;p.1&gt; \\n 2024 BITAmin 겨울 연합프로젝트 시계열 1조 \\n Netf...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;p.2&gt; \\n CONTENTS \\n 01. INTRODUCTION \\n 02. D...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;p.3&gt; \\n 01. INTRODUCTION \\n  \\n</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;p.4&gt; \\n 01. INTRODUCTION \\n 1.1 Background of...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;p.5&gt; \\n 01. INTRODUCTION \\n 1.1 Background of...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>&lt;p.6&gt; \\n 01. INTRODUCTION \\n 1.2 Brief Project...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&lt;p.7&gt; \\n 01. INTRODUCTION \\n 1.3 Data collecti...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>&lt;p.8&gt; \\n 01. INTRODUCTION \\n 1.3 Data collecti...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>&lt;p.9&gt; \\n 01. INTRODUCTION \\n 1.3 Data collecti...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>&lt;p.10&gt; \\n 02. DATA PREPROCESSING \\n  \\n</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>&lt;p.11&gt; \\n 02. DATA PREPROCESING \\n 2.1 Make de...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>&lt;p.12&gt; \\n 02. DATA PREPROCESING \\n 2.2 Add ind...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>&lt;p.13&gt; \\n 02. DATA PREPROCESING \\n 2.2 Add ind...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>&lt;p.14&gt; \\n 02. DATA PREPROCESING \\n 2.3 Peer An...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>&lt;p.15&gt; \\n 02. DATA PREPROCESING \\n 2.3 Peer An...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>&lt;p.16&gt; \\n 02. DATA PREPROCESING \\n 2.4 Remove ...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>&lt;p.17&gt; \\n 02. DATA PREPROCESING \\n 2.5 Make de...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>&lt;p.18&gt; \\n 02. DATA PREPROCESING \\n 2.6 Dataset...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>&lt;p.19&gt; \\n 02. DATA PREPROCESING \\n 2.6 Dataset...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>&lt;p.20&gt; \\n 03. MODELING \\n  \\n</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>&lt;p.21&gt; \\n 03. MODELING \\n 3.1 Time Series  \\n ...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>&lt;p.22&gt; \\n 03. MODELING \\n 3.2 Modeling  \\n Ste...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>&lt;p.23&gt; \\n 03. MODELING \\n 3.2 Modeling  \\n Ste...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>&lt;p.24&gt; \\n 03. MODELING \\n 3.2 Modeling  \\n Ste...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>&lt;p.25&gt; \\n 03. MODELING \\n 3.2 Modeling  \\n Ste...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>&lt;p.26&gt; \\n 03. MODELING \\n 3.2 Modeling  \\n Ste...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>&lt;p.27&gt; \\n 04. CONCLUSION AND LIMITATION \\n  \\n</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>&lt;p.28&gt; \\n 04. CONCLUSIONS AND LIMITATIONS \\n 4...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>&lt;p.29&gt; \\n 04. CONCLUSIONS AND LIMITATIONS \\n 4...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>&lt;p.30&gt; \\n 04. CONCLUSIONS AND LIMITATIONS \\n 4...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>&lt;p.31&gt; \\n 04. CONCLUSIONS AND LIMITATIONS \\n 4...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>&lt;p.32&gt; \\n 04. CONCLUSIONS AND LIMITATIONS \\n 4...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>&lt;p.33&gt; \\n 04. CONCLUSIONS AND LIMITATIONS \\n 4...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>&lt;p.34&gt; \\n 04. CONCLUSIONS AND LIMITATIONS \\n 4...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>&lt;p.35&gt; \\n 04. CONCLUSIONS AND LIMITATIONS \\n 4...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>&lt;p.36&gt; \\n 04. CONCLUSIONS AND LIMITATIONS \\n 4...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>&lt;p.37&gt; \\n 04. CONCLUSIONS AND LIMITATIONS \\n 4...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>&lt;p.38&gt; \\n 04. CONCLUSIONS AND LIMITATIONS \\n 4...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>&lt;p.39&gt; \\n 04. CONCLUSIONS AND LIMITATIONS \\n 4...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>&lt;p.40&gt; \\n 04. CONCLUSIONS AND LIMITATIONS \\n 4...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>&lt;p.41&gt; \\n2024 BITAmin 겨울 연합프로젝트 시계열 1조 \\nTHANK...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text kmeans  new_cluster  \\\n",
       "0   <p.1> \\n 2024 BITAmin 겨울 연합프로젝트 시계열 1조 \\n Netf...      4            0   \n",
       "1   <p.2> \\n CONTENTS \\n 01. INTRODUCTION \\n 02. D...      1            1   \n",
       "2                    <p.3> \\n 01. INTRODUCTION \\n  \\n      1            1   \n",
       "3   <p.4> \\n 01. INTRODUCTION \\n 1.1 Background of...      5            2   \n",
       "4   <p.5> \\n 01. INTRODUCTION \\n 1.1 Background of...      2            3   \n",
       "5   <p.6> \\n 01. INTRODUCTION \\n 1.2 Brief Project...      5            2   \n",
       "6   <p.7> \\n 01. INTRODUCTION \\n 1.3 Data collecti...      4            0   \n",
       "7   <p.8> \\n 01. INTRODUCTION \\n 1.3 Data collecti...      2            3   \n",
       "8   <p.9> \\n 01. INTRODUCTION \\n 1.3 Data collecti...      4            0   \n",
       "9             <p.10> \\n 02. DATA PREPROCESSING \\n  \\n      1            1   \n",
       "10  <p.11> \\n 02. DATA PREPROCESING \\n 2.1 Make de...      3            4   \n",
       "11  <p.12> \\n 02. DATA PREPROCESING \\n 2.2 Add ind...      4            0   \n",
       "12  <p.13> \\n 02. DATA PREPROCESING \\n 2.2 Add ind...      3            4   \n",
       "13  <p.14> \\n 02. DATA PREPROCESING \\n 2.3 Peer An...      2            3   \n",
       "14  <p.15> \\n 02. DATA PREPROCESING \\n 2.3 Peer An...      2            3   \n",
       "15  <p.16> \\n 02. DATA PREPROCESING \\n 2.4 Remove ...      3            4   \n",
       "16  <p.17> \\n 02. DATA PREPROCESING \\n 2.5 Make de...      3            4   \n",
       "17  <p.18> \\n 02. DATA PREPROCESING \\n 2.6 Dataset...      2            3   \n",
       "18  <p.19> \\n 02. DATA PREPROCESING \\n 2.6 Dataset...      4            0   \n",
       "19                      <p.20> \\n 03. MODELING \\n  \\n      1            1   \n",
       "20  <p.21> \\n 03. MODELING \\n 3.1 Time Series  \\n ...      2            3   \n",
       "21  <p.22> \\n 03. MODELING \\n 3.2 Modeling  \\n Ste...      4            0   \n",
       "22  <p.23> \\n 03. MODELING \\n 3.2 Modeling  \\n Ste...      5            2   \n",
       "23  <p.24> \\n 03. MODELING \\n 3.2 Modeling  \\n Ste...      4            0   \n",
       "24  <p.25> \\n 03. MODELING \\n 3.2 Modeling  \\n Ste...      4            0   \n",
       "25  <p.26> \\n 03. MODELING \\n 3.2 Modeling  \\n Ste...      5            2   \n",
       "26     <p.27> \\n 04. CONCLUSION AND LIMITATION \\n  \\n      0            5   \n",
       "27  <p.28> \\n 04. CONCLUSIONS AND LIMITATIONS \\n 4...      0            5   \n",
       "28  <p.29> \\n 04. CONCLUSIONS AND LIMITATIONS \\n 4...      2            3   \n",
       "29  <p.30> \\n 04. CONCLUSIONS AND LIMITATIONS \\n 4...      5            2   \n",
       "30  <p.31> \\n 04. CONCLUSIONS AND LIMITATIONS \\n 4...      1            1   \n",
       "31  <p.32> \\n 04. CONCLUSIONS AND LIMITATIONS \\n 4...      1            1   \n",
       "32  <p.33> \\n 04. CONCLUSIONS AND LIMITATIONS \\n 4...      1            1   \n",
       "33  <p.34> \\n 04. CONCLUSIONS AND LIMITATIONS \\n 4...      5            2   \n",
       "34  <p.35> \\n 04. CONCLUSIONS AND LIMITATIONS \\n 4...      2            3   \n",
       "35  <p.36> \\n 04. CONCLUSIONS AND LIMITATIONS \\n 4...      3            4   \n",
       "36  <p.37> \\n 04. CONCLUSIONS AND LIMITATIONS \\n 4...      0            5   \n",
       "37  <p.38> \\n 04. CONCLUSIONS AND LIMITATIONS \\n 4...      4            0   \n",
       "38  <p.39> \\n 04. CONCLUSIONS AND LIMITATIONS \\n 4...      4            0   \n",
       "39  <p.40> \\n 04. CONCLUSIONS AND LIMITATIONS \\n 4...      3            4   \n",
       "40  <p.41> \\n2024 BITAmin 겨울 연합프로젝트 시계열 1조 \\nTHANK...      2            3   \n",
       "\n",
       "    target  \n",
       "0        0  \n",
       "1        0  \n",
       "2        1  \n",
       "3        1  \n",
       "4        1  \n",
       "5        1  \n",
       "6        1  \n",
       "7        1  \n",
       "8        1  \n",
       "9        2  \n",
       "10       2  \n",
       "11       2  \n",
       "12       2  \n",
       "13       2  \n",
       "14       2  \n",
       "15       2  \n",
       "16       2  \n",
       "17       2  \n",
       "18       2  \n",
       "19       3  \n",
       "20       3  \n",
       "21       3  \n",
       "22       3  \n",
       "23       3  \n",
       "24       3  \n",
       "25       3  \n",
       "26       4  \n",
       "27       4  \n",
       "28       4  \n",
       "29       4  \n",
       "30       4  \n",
       "31       4  \n",
       "32       4  \n",
       "33       4  \n",
       "34       4  \n",
       "35       4  \n",
       "36       4  \n",
       "37       4  \n",
       "38       4  \n",
       "39       4  \n",
       "40       5  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2_renew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "71fb3e0c-f7be-4618-b9fd-41678fce5185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spectral</th>\n",
       "      <th>new_cluster</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;p.1&gt; \\n 비타민 11기 겨울 컨퍼런스 \\n LLM 기반 거짓말 탐지기 \\n ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;p.2&gt; \\n 서비스 배경 및 기획 | 모델 구축 과정 | 결론 및 제언 \\n 서...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;p.3&gt; \\n 서비스 배경 및 기획 ► 문제 상황 \\n 비타민 11기 겨울 컨퍼런...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;p.4&gt; \\n 서비스 배경 및 기획 ► 문제 상황 \\n 비타민 11기 겨울 컨퍼런...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;p.5&gt; \\n 서비스 배경 및 기획 ► 문제 상황 \\n 비타민 11기 겨울 컨퍼런...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>&lt;p.6&gt; \\n 서비스 배경 및 기획 ► 서비스 제안 및 사용 예시 \\n 비타민 1...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&lt;p.7&gt; \\n 서비스 배경 및 기획 ► 실무 파이프라인 \\n 비타민 11기 겨울 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>&lt;p.8&gt; \\n RAG Retrieval –Augmented Generation \\...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>&lt;p.9&gt; \\n PEFT Parameter Efficient Fine Tuning ...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>&lt;p.10&gt; \\n 비타민 11기 겨울 컨퍼런스 \\n 서비스 배경 및 기획 | 모델 ...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>&lt;p.11&gt; \\n 모델 구축 과정 ► STT 구현 \\n 비타민 11기 겨울 컨퍼런스...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>&lt;p.12&gt; \\n 모델 구축 과정 ► STT 구현 \\n 비타민 11기 겨울 컨퍼런스...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>&lt;p.13&gt; \\n 모델 구축 과정 ► 데이터 구축 \\n 비타민 11기 겨울 컨퍼런스...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>&lt;p.14&gt; \\n 모델 구축 과정 ► 데이터 구축 \\n 비타민 11기 겨울 컨퍼런스...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>&lt;p.15&gt; \\n 모델 구축 과정 ► 데이터 구축 \\n 비타민 11기 겨울 컨퍼런스...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>&lt;p.16&gt; \\n 모델 구축 과정 ► 데이터 구축 \\n 비타민 11기 겨울 컨퍼런스...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>&lt;p.17&gt; \\n 모델 구축 과정 ► 데이터 구축 \\n 비타민 11기 겨울 컨퍼런스...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>&lt;p.18&gt; \\n 모델 구축 과정 ► 데이터 구축 \\n 비타민 11기 겨울 컨퍼런스...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>&lt;p.19&gt; \\n 모델 구축 과정 ► 데이터 구축 \\n 비타민 11기 겨울 컨퍼런스...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>&lt;p.20&gt; \\n 모델 구축 과정 ► Fine Tuning \\n 비타민 11기 겨울...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>&lt;p.21&gt; \\n 모델 구축 과정 ► Fine Tuning \\n 비타민 11기 겨울...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>&lt;p.22&gt; \\n 모델 구축 과정 ► Fine Tuning \\n 비타민 11기 겨울...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>&lt;p.23&gt; \\n 모델 구축 과정 ► Fine Tuning \\n 비타민 11기 겨울...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>&lt;p.24&gt; \\n 모델 구축 과정 ► Fine Tuning \\n 비타민 11기 겨울...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>&lt;p.25&gt; \\n 모델 구축 과정 ► Fine Tuning \\n 비타민 11기 겨울...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>&lt;p.26&gt; \\n 모델 구축 과정 ► RAG \\n 비타민 11기 겨울 컨퍼런스 \\n...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>&lt;p.27&gt; \\n 모델 구축 과정 ► RAG \\n 비타민 11기 겨울 컨퍼런스 \\n...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>&lt;p.28&gt; \\n 비타민 11기 겨울 컨퍼런스 \\n 서비스 배경 및 기획 | 모델 ...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>&lt;p.29&gt; \\n 결론 및 제언 ► 프로젝트 의의 \\n 비타민 11기 겨울 컨퍼런스...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>&lt;p.30&gt; \\n 결론 및 제언 ► 프로젝트 의의 \\n 비타민 11기 겨울 컨퍼런스...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>&lt;p.31&gt; \\nEnd of Document \\n팀원 | 조민호 박소연 박준형 박세...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text spectral  new_cluster  \\\n",
       "0   <p.1> \\n 비타민 11기 겨울 컨퍼런스 \\n LLM 기반 거짓말 탐지기 \\n ...        0            0   \n",
       "1   <p.2> \\n 서비스 배경 및 기획 | 모델 구축 과정 | 결론 및 제언 \\n 서...        4            1   \n",
       "2   <p.3> \\n 서비스 배경 및 기획 ► 문제 상황 \\n 비타민 11기 겨울 컨퍼런...        4            1   \n",
       "3   <p.4> \\n 서비스 배경 및 기획 ► 문제 상황 \\n 비타민 11기 겨울 컨퍼런...        2            2   \n",
       "4   <p.5> \\n 서비스 배경 및 기획 ► 문제 상황 \\n 비타민 11기 겨울 컨퍼런...        0            0   \n",
       "5   <p.6> \\n 서비스 배경 및 기획 ► 서비스 제안 및 사용 예시 \\n 비타민 1...        1            3   \n",
       "6   <p.7> \\n 서비스 배경 및 기획 ► 실무 파이프라인 \\n 비타민 11기 겨울 ...        0            0   \n",
       "7   <p.8> \\n RAG Retrieval –Augmented Generation \\...        1            3   \n",
       "8   <p.9> \\n PEFT Parameter Efficient Fine Tuning ...        1            3   \n",
       "9   <p.10> \\n 비타민 11기 겨울 컨퍼런스 \\n 서비스 배경 및 기획 | 모델 ...        4            1   \n",
       "10  <p.11> \\n 모델 구축 과정 ► STT 구현 \\n 비타민 11기 겨울 컨퍼런스...        3            4   \n",
       "11  <p.12> \\n 모델 구축 과정 ► STT 구현 \\n 비타민 11기 겨울 컨퍼런스...        2            2   \n",
       "12  <p.13> \\n 모델 구축 과정 ► 데이터 구축 \\n 비타민 11기 겨울 컨퍼런스...        3            4   \n",
       "13  <p.14> \\n 모델 구축 과정 ► 데이터 구축 \\n 비타민 11기 겨울 컨퍼런스...        0            0   \n",
       "14  <p.15> \\n 모델 구축 과정 ► 데이터 구축 \\n 비타민 11기 겨울 컨퍼런스...        2            2   \n",
       "15  <p.16> \\n 모델 구축 과정 ► 데이터 구축 \\n 비타민 11기 겨울 컨퍼런스...        3            4   \n",
       "16  <p.17> \\n 모델 구축 과정 ► 데이터 구축 \\n 비타민 11기 겨울 컨퍼런스...        2            2   \n",
       "17  <p.18> \\n 모델 구축 과정 ► 데이터 구축 \\n 비타민 11기 겨울 컨퍼런스...        2            2   \n",
       "18  <p.19> \\n 모델 구축 과정 ► 데이터 구축 \\n 비타민 11기 겨울 컨퍼런스...        4            1   \n",
       "19  <p.20> \\n 모델 구축 과정 ► Fine Tuning \\n 비타민 11기 겨울...        3            4   \n",
       "20  <p.21> \\n 모델 구축 과정 ► Fine Tuning \\n 비타민 11기 겨울...        1            3   \n",
       "21  <p.22> \\n 모델 구축 과정 ► Fine Tuning \\n 비타민 11기 겨울...        1            3   \n",
       "22  <p.23> \\n 모델 구축 과정 ► Fine Tuning \\n 비타민 11기 겨울...        2            2   \n",
       "23  <p.24> \\n 모델 구축 과정 ► Fine Tuning \\n 비타민 11기 겨울...        0            0   \n",
       "24  <p.25> \\n 모델 구축 과정 ► Fine Tuning \\n 비타민 11기 겨울...        3            4   \n",
       "25  <p.26> \\n 모델 구축 과정 ► RAG \\n 비타민 11기 겨울 컨퍼런스 \\n...        1            3   \n",
       "26  <p.27> \\n 모델 구축 과정 ► RAG \\n 비타민 11기 겨울 컨퍼런스 \\n...        1            3   \n",
       "27  <p.28> \\n 비타민 11기 겨울 컨퍼런스 \\n 서비스 배경 및 기획 | 모델 ...        4            1   \n",
       "28  <p.29> \\n 결론 및 제언 ► 프로젝트 의의 \\n 비타민 11기 겨울 컨퍼런스...        1            3   \n",
       "29  <p.30> \\n 결론 및 제언 ► 프로젝트 의의 \\n 비타민 11기 겨울 컨퍼런스...        0            0   \n",
       "30  <p.31> \\nEnd of Document \\n팀원 | 조민호 박소연 박준형 박세...        3            4   \n",
       "\n",
       "    target  \n",
       "0        0  \n",
       "1        0  \n",
       "2        1  \n",
       "3        1  \n",
       "4        1  \n",
       "5        1  \n",
       "6        1  \n",
       "7        1  \n",
       "8        1  \n",
       "9        2  \n",
       "10       2  \n",
       "11       2  \n",
       "12       2  \n",
       "13       2  \n",
       "14       2  \n",
       "15       2  \n",
       "16       2  \n",
       "17       2  \n",
       "18       2  \n",
       "19       2  \n",
       "20       2  \n",
       "21       2  \n",
       "22       2  \n",
       "23       2  \n",
       "24       2  \n",
       "25       2  \n",
       "26       2  \n",
       "27       3  \n",
       "28       3  \n",
       "29       3  \n",
       "30       4  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_renew"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
