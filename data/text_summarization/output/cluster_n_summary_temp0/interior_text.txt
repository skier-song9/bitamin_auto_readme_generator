<subject>도배 하자 질의 응답 처리 및 LLM 개발에 관한 프로젝트</subject>
<team>구준회, 김지원, 박서진, 신진섭, 엄성원</team>
<index>프로젝트 배경, EDA, Text Augmentation, Modeling & Inference, 보완할 점 & 추후계획</index>
<main>프로젝트 배경</main>
<sub>[목표]</sub>
<content>자연어를 처리하여 언어모델에 학습시키고, 특정 TASK에 적합한 TEXT를 생성하는 원리를 이해하는 것이 목표이다.</content>

<sub>[Issues]</sub>
<content>한정된 GPU 자원(예: Kaggle Notebook, Colab T4, RAM 16GB)으로 인해 성능에 제약이 있으며, 파라미터 수가 큰 모델은 한국어 데이터로 사전훈련되지 않았더라도 높은 성능을 기대할 수 있다.</content>
<main> EDA</main>
<sub>Overall Progress</sub>
<content>전체 진행 상황은 NLP 도메인에 대한 이해와 Transformer 모델을 활용한 질의 응답 시스템 개발을 포함하며, 공모전 목표에 맞춰 언어 모델을 개발하고 추론하는 과정이 강조된다.</content>

<sub>Modeling</sub>
<content>모델링 단계에서는 SFT(Supervised Fine Tuning)와 Prompting을 통해 LLM에 특정 작업에 적합한 지시를 주어 대답을 형성하는 방법이 설명된다.</content>

<sub>Fine Tuning</sub>
<content>Fine Tuning은 사전 학습된 모델을 소규모의 특정 데이터 세트에 대해 추가로 학습시켜 특정 작업이나 도메인에서 성능을 향상시키는 프로세스를 의미한다.</content>
<main> Text Augmentation</main>
<sub>Train Data</sub>
<content>EDA 주최 측에서 제공하는 트레인 데이터는 질문 2개와 그에 대한 5개의 카테고리 답변으로 구성되어 있으며, 이를 통해 데이터의 구조를 이해할 수 있다.</content>

<sub>Tokenization</sub>
<content>질문과 답변 세트를 토큰화하여 입력으로 사용함으로써, 텍스트 증강을 위한 데이터 전처리 과정이 이루어진다.</content>
<main> Modeling & Inference</main>
<sub>Modeling LORA PEFT</sub>
<content>LoRA PEFT는 적은 매개변수로 빠르게 새로운 문제를 해결하는 fine-tuning 기법으로, 대부분의 매개변수 가중치를 유지하면서 일부만 미세조정하여 훈련 비용과 컴퓨팅 리소스를 절약하면서 성능을 향상시킬 수 있다.</content>

<sub>Query 가중치에 대해 LoRA 적용</sub>
<content>LoRA를 적용하여 query 가중치를 조정함으로써 모델의 성능을 개선하고, fine-tuned model이 주어진 질문에 대해 더 구체적이고 유의미한 답변을 생성하도록 한다.</content>

<sub>Inference</sub>
<content>Inference 과정에서 fine-tuned model은 주어진 질문에 대한 구체적인 답변을 생성하기 위해 instruction을 부여받으며, 이를 통해 학습된 정보를 바탕으로 보다 정확한 답변을 제공한다.</content>
<main> 보완할 점 & 추후계획</main>
<sub>보완할 점</sub>
<content>현재 시스템의 사용자 인터페이스가 직관적이지 않아 사용자 경험을 저해하고 있으며, 이를 개선할 필요가 있다.</content>

<sub>추후계획</sub>
<content>향후 업데이트에서는 사용자 피드백을 반영하여 인터페이스를 개선하고, 기능 추가를 통해 전반적인 성능을 향상시킬 계획이다.</content>