<subject>GAN</subject>  
<team>이하나, 김하니</team>  
<index>GAN이란?, 손실함수</index>  

<main>GAN이란?</main>  
<sub>GAN이란?</sub> <content>GAN의 훈련 과정은 적대적 훈련으로, Generator는 진짜 같은 이미지를 생성하여 Discriminator를 속이는 것을 목표로 한다.</content> <page>4</page>  
<sub>손실함수</sub> <content>Generator와 Discriminator 간의 경쟁을 통해 Generator가 진짜 같은 이미지를 생성하도록 학습하며, 손실 함수를 최소화하는 것이 학습 목표가 아니다.</content> <page>5</page>  

<main>CartoonGAN</main>  
<sub>Architecture</sub> <content>CartoonGAN의 아키텍처는 Generator가 실제 사진을 입력으로 받아 고수준 특징을 유지하며 스타일 변환을 수행한다.</content> <page>8</page>  
<sub>Loss function</sub> <content>손실 함수는 생성된 만화 이미지가 실제 만화 이미지로 분류되고, 실제 사진이 가짜로 분류되도록 판별기를 학습시키는 역할을 한다.</content> <page>9</page>  

<main>Dataset</main>  
<sub>Dataset</sub> <content>총 9728장의 만화 이미지와 10000장의 실제 이미지로 구성되며, 만화 이미지는 One Piece 영화에서 추출되었다.</content> <page>11</page>  

<main>CartoonGAN 변형</main>  
<sub>변형 CartoonGAN ResNet Block</sub> <content>Generator의 ResNet Block에 배치 정규화와 잔차 연결 후 ReLU가 적용되는 구조를 사용한다.</content> <page>14</page>  
<sub>변형 CartoonGAN Generator Upsampling</sub> <content>Generator에서 blurring과 배치 정규화를 사용하여 upsampling 과정의 checkerboard 문제를 해결한다.</content> <page>15</page>  
<sub>변형 CartoonGAN Content Loss</sub> <content>VGG16을 사용하여 feature extractor로 계산 비용을 줄인다.</content> <page>16</page>  

<main>Experiment</main>  
<sub>Experiment Train</sub> <content>Generator는 사전 훈련되고, 10 epochs, 배치 크기 16, AdamW 옵티마이저, 학습률 0.0001로 학습된다.</content> <page>18</page>  
<sub>Experiment Train Presentation</sub> <content>Discriminator와 Generator는 각각 10 epochs 동안 훈련되며, 손실 함수는 Adversarial Loss와 Content Loss를 포함한다.</content> <page>19</page>  
<sub>Experiment Results</sub> <content>최종 모델 결과로 실제 이미지와 생성된 만화 이미지 간의 고수준 특징 차이가 최소화되었고, 판별기의 정확도가 높게 유지되었다.</content> <page>20</page>