<subject>도배 하자 질의 응답 처리 한솔데코 시즌 2 Al 경진대회 알고리즘 언어 - LLM MLOps OA - Cosine Similarity, 도배하자 질의응답 LLM 개발</subject>
<team>구준회, 김지원, 박서진, 신진섭, 엄성원</team>
<index>프로젝트 배경, EDA, Text Augmentation, Modeling & Inference, 보완할 점 & 추후계획</index>
<main>프로젝트 배경</main>
<subtitle>[목표]</subtitle>
<content>자연어를 처리하여 언어모델에 학습시키고 특정 TASK에 적합한 TEXT를 생성하는 원리를 이해하는 것이 목표이다.</content>

<subtitle>[Overall Progress]</subtitle>
<content>NLP 도메인에 대한 이해를 바탕으로 Transformer 및 질의 응답 관련 논문 공부를 통해 언어모델 개발 및 추론에 대한 방향을 설정하고 있다.</content>
<main> EDA</main>
<subtitle>[Train Data]</subtitle>
<content>EDA에서 사용되는 학습 데이터는 id, 카테고리, 질문, 답변을 포함한 5개 열로 구성되어 있으며, 질문과 답변 세트를 토큰화하여 입력으로 사용한다.</content>

<subtitle>[Text Augmentation]</subtitle>
<content>질문 생성을 위해 다양한 소스에서 전문적인 키워드를 탐색하고, 자주 묻는 질문을 실용적으로 탐색하여 질문의 다양성을 높인다.</content>

<subtitle>[Crawling & Prompt Engineering]</subtitle>
<content>ChatGPT를 활용하여 도배업계 전문가가 일반인을 대상으로 질문에 대해 200글자 이내의 전문적인 답변 5가지를 생성할 수 있도록 한다.</content>
<main> Text Augmentation</main>
<subtitle>최종 train dataset</subtitle>
<content>기존의 6440개의 QA 세트가 데이터 증강을 통해 8319개의 QA 세트로 증가하였다.</content>
<main> Modeling & Inference</main>
<subtitle>[Modeling Fine Tuning]</subtitle>
<content>Fine Tuning은 사전 학습된 모델을 특정 데이터 세트에 추가로 학습시켜 특정 작업이나 도메인에서 성능을 향상시키는 과정이다. 이 방법은 generic task에서 specific task로의 전환을 용이하게 한다.</content>

<subtitle>[Modeling LORA PEFT]</subtitle>
<content>LoRA(Low-Rank Adaptation)와 PEFT(Parameter Efficient Fine-Tuning)는 적은 파라미터로 모델을 빠르게 fine-tuning할 수 있는 기법이다. 이는 대부분의 가중치를 유지하면서 일부만 조정하여 훈련 비용과 자원을 절약하면서도 특정 작업 성능을 개선하는 데 도움을 준다.</content>

<subtitle>[Inference]</subtitle>
<content>Fine-tuned model은 주어진 질문에 대해 instruction을 포함한 input을 통해 구체적인 답변을 생성하도록 설계되며, 이는 학습된 정보를 바탕으로 질문의 장점에 대한 답을 효과적으로 제공한다.</content>
<main> 보완할 점 & 추후계획</main>
<subtitle>[보완할 점]</subtitle>
<content>현재 시스템의 사용자 경험을 개선하기 위해 피드백을 반영하고, 인터페이스의 직관성을 높일 필요가 있다.</content>

<subtitle>[추후계획]</subtitle>
<content>다음 단계로는 기능 확장을 위한 업데이트와 사용자 의견 수렴을 통해 지속적으로 개선점을 찾아내고 반영할 계획이다.</content>