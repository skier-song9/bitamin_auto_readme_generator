<subject>시각장애인을 위한 음성 안내 카메라 서비스</subject>
<team>김지원, 박석우, 박소언, 배성윤</team>
<index>서비스 목표, 플로우 및 기능설명, 한계점</index>
<main>서비스 목표</main>
<sub>서비스 제공 목적</sub>
<content>시각장애인 이용자가 음성 안내를 통해 보다 수월하게 사진을 촬영할 수 있도록 지원하는 서비스의 제공을 목표로 한다.</content>

<sub>구체적 위치 안내</sub>
<content>이용자에게 위아래 객체의 구체적인 위치 정보를 제공하여 더욱 효과적인 사진 촬영이 가능하도록 한다.</content>

<sub>프로젝트 목표</sub>
<content>사진기 음성 안내를 위해 얼굴 탐지 모델의 정확도를 향상시키고, 실시간 추론 속도를 개선하며, 탐지된 객체의 정보를 적절한 시점에 음성으로 안내하는 알고리즘을 최적화하는 것을 목표로 한다.</content>

<sub>자율성과 사회적 참여 향상</sub>
<content>음성 안내를 통해 시각장애인의 사진 촬영 정확성과 효율성을 높이며, 이들의 자율성과 사회적 참여를 크게 향상시키는 데 기여한다.</content>
<main> 플로우 및 기능설명</main>
<sub>텍스트 음성 변환 (TTS)</sub>
<content>화면에 잡힌 얼굴의 위치를 인식하고, 시선 방향 및 각도를 파악한 후, 얼굴의 위치와 방향성 각도를 TTS로 안내한다.</content>

<sub>객체 인식</sub>
<content>최대 3개의 객체를 인식하고, 각 객체의 레이블과 위치를 TTS로 안내하며, 단일 객체인 경우에는 해당 객체의 레이블과 화면 차지 비중을 함께 안내한다.</content>

<sub>객체 탐지 모델 선정</sub>
<content>후면 카메라의 경우, 최적의 추론 속도를 위해 사전 훈련된 YOLOV 모델을 사용하며, 조명 환경에서 성능 향상을 위해 데이터 증강 라이브러리를 활용한다.</content>

<sub>음성 안내 알고리즘</sub>
<content>전면 카메라는 이전 프레임의 bbox와의 IoU를 계산하여 음성 안내의 정확성을 높이고, 후면 카메라는 높은 신뢰도를 가진 세 가지 객체만 인식하여 안내한다.</content>

<sub>움직임 안정화 판단 함수</sub>
<content>후면 카메라를 위한 IOU 함수 정의와 추가적인 스케일링을 통해 안정적인 객체 인식을 보장하고, FPS를 고려하여 프레임 단위로 bbox를 업데이트한다.</content>
<main> 한계점</main>
<sub>음성 안내 도중에 변동사항 반영x</sub>
<content>변동 사항이 발생하고도 음성 안내 시스템이 이를 반영하지 못하는 문제가 있으며, 이는 정보가 동적으로 변하는 상황에서 안내의 실효성을 떨어뜨릴 수 있다.</content>

<sub>안내되는 비율 수치의 상대성</sub>
<content>비율 정보가 수치로만 제공되기 때문에 시각 장애인에게 불편함을 초래하며, 사용성 측면에서 보다 효과적인 접근법이 필요하다.</content>

<sub>TTS 구현 모률인 Pyttsx3 특성상 음성 재생 도중에 중단 불가</sub>
<content>Pyttsx3의 특성으로 인해 음성 재생 도중 안내를 중단할 수 없어, 변화하는 상황에 대한 적절한 반응이 어렵다.</content>

<sub>추가적인 사용자의 움직임 감지로 입력 정보가 변하면 안내를 중단하고 싶었지만 구현 실패</sub>
<content>사용자의 움직임을 감지하여 입력 정보가 변할 경우 안내를 중단하려 했으나, 기술적 한계로 인해 이를 구현하지 못하였다.</content>

<sub>카메라 프레임 규격 조정X</sub>
<content>웹캠의 프레임 규격을 기준으로 모델이 학습되었으며, 이는 특정 규격에 한정되어 사용할 수 있음을 의미한다.</content>

<sub>객체 Iabel의 한정성</sub>
<content>모델이 탐지한 물체의 라벨이 제한적이기 때문에, 차지 비율이 높은 경우에도 정확한 라벨링이 이루어지지 않을 수 있다.</content>