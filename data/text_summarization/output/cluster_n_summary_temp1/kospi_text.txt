<subject>비타민 12 & 13기 학기 프로젝트의 피쳐 중요도를 통한 KOSPI 지수 예측 분석</subject>
<team>None</team>
<index>비타민 학기 프로젝트 최종 발표 목차, LEVEL 2 모델 소개 XGB LSTM GRU, EVEL 3 피쳐 중요도 분석 Attention SHAP, LEVEL 4 결과 비교 및 결론</index>
<main>비타민 학기 프로젝트 최종 발표 목차</main>
<subtitle>피쳐 중요도 분석을 통한 KOSPI 지수 예측</subtitle>
<content>KOSPI 지수 예측을 위한 피쳐 중요도 분석을 수행하였으며, 다양한 모델인 XGBLSTM과 GRU를 사용하여 예측 정확도를 평가하였다. 하이퍼 파라미터 튜닝 결과, 종가 데이터와 변화율 데이터의 정확도를 비교하며 성능 개선을 확인하였다.</content>

<subtitle>모델 고개</subtitle>
<content>XGBLSTM과 GRU 모델을 포함한 다양한 모델을 구축하였으며, 종가 데이터와 변화율 데이터에 대한 하이퍼 파라미터 튜닝의 결과가 제시되었다. 변화율 데이터를 사용할 경우 약 0.05의 성능 개선이 관찰되었다.</content>

<subtitle>SHAP 분석</subtitle>
<content>SHAP 값을 활용하여 피쳐 간의 상호작용을 분석한 결과, 피쳐 간의 상호작용 정도는 미미한 것으로 나타났다. 종가는 변화율과의 관계에서 상호작용이 크지 않음을 확인하였다.</content>

<subtitle>결론</subtitle>
<content>피쳐 중요도 분석을 통해 KOSPI 예측 모델의 성능을 비교한 결과가 보고되었으며, 종가와 변화율 데이터 간의 예측 성능 차이에 대한 논의가 포함되었다. 또한 Attention 기법을 활용한 피쳐 중요도 분석도 언급되었다.</content>
<main> LEVEL 2 모델 소개 XGB LSTM GRU</main>
<subtitle>ESTM 구축</subtitle>
<content>두 개의 LSTM 레이어를 사용하며, 각 레이어 후에 드롭아웃을 추가하여 과적합을 방지하고 콜백을 통해 가장 좋은 가중치를 복원하는 EarlyStopping 기법을 적용함.</content>

<subtitle>GRU 구축</subtitle>
<content>두 개의 GRU 레이어를 사용하고, 각 레이어 후에 드롭아웃을 추가하여 과적합을 방지하며, 콜백을 통해 가장 좋은 가중치를 복원하는 EarlyStopping 기법을 활용함.</content>

<subtitle>피쳐 중요도 분석을 통한 KOSPI 지수 예측</subtitle>
<content>XGBoost가 가장 우수한 성능을 보여주며, 변화율 데이터를 사용하여 성능이 향상된 경우, 이는 변화율 데이터가 종가 데이터보다 유의미한 패턴과 트렌드를 제공하여 모델의 예측 정확도를 높이는데 기여함을 확인함.</content>
<main> EVEL 3 피쳐 중요도 분석 Attention SHAP</main>
<subtitle>데이터 전처리</subtitle>
<content>종가 데이터 및 다양한 외부 지표를 사용하여 데이터프레임을 병합하고 결측치를 처리한 후, 슬라이딩 윈도우 기법을 통해 시간적 순서를 유지하며 미래 예측을 위한 데이터를 생성하였다.</content>

<subtitle>Attention</subtitle>
<content>Transformer 블록을 활용한 모델을 정의하고, 각 레이어로부터 가중치를 추출하여 Attention 기법을 통해 중요한 정보를 선택하였다.</content>

<subtitle>SHAP 변수 중요도 분석</subtitle>
<content>SHAP 결과를 기반으로 상위 피쳐를 선정하여 모델링을 진행하였으며, 기존 모델 성능을 비슷하게 유지하면서도 피쳐 수를 대폭 줄일 수 있었다.</content>

<subtitle>결과 비교</subtitle>
<content>Xgboost와 LSTM 모델의 성능을 비교하였고, 변수 중요도 계수를 적용한 데이터 세트에서 Xgboost가 우수한 성능을 보였으며, 중요도 계수가 양수인 경우 LSTM의 성능이 개선되었다.</content>
<main> LEVEL 4 결과 비교 및 결론</main>
<subtitle>결과 비교</subtitle>
<content>XGBoost가 가장 우수한 성능을 보여주었으며, LSTM과 GRU는 변수 중요도를 적용한 데이터셋에서 약간의 성능 향상이 있었고, Attention을 이용한 feature 적용 결과는 LSTM, GRU에 성능 증가를 가져왔지만 XGBoost에서는 약간의 성능 하락을 초래했다.</content>

<subtitle>결론</subtitle>
<content>변화율 데이터를 활용한 주가 예측이 종가 데이터보다 정확한 성능을 보이며, Attention 메커니즘을 통해 변수 중요도를 분석하고 LSTM, GRU의 예측 성능을 향상시킬 수 있다. 변수 중요도 분석을 통해 적은 피쳐만으로도 모델 성능을 유지할 수 있는 점이 주목할 만하다.</content>