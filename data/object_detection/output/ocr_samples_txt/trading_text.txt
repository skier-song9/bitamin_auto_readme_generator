<p.01>
 을홀 '시' 계을 |측 과 학 할용 한 피미 여 강호 습을 시 템 트 레 이딩 익 수 극도 화
 BTAMIN PROJECT
 시계열 3조 송규헌 송휘종 서영우 이태경 정유진 정준우
<p.02>
 목차
 주제 03
 NorkFlow 09
 종목 선정
 시스템 트레이딩
 데이터수집및 전처리 05
 데이터수집 및 전처리 12
 시계열 모델
 강화학습 모델
 모델 평가및 선정 07
 시스템 트레이딩 15
 결과 16
<p.03>
 [주제]
 시계열 예측과 트레이딩 수익 극대화 강화학습을 활용한시스템
 기존 금융 덥러닝의 실패 요인들
 노이즈가 심하다 2 데이터 수가 부족하다 마이크로소프트으 상장일1986년 3월 13일~현재까지의 주식 일봉 데이터 개수는 9491개 뿐이다 3 12번으로 인한 과적합이 심하다
 9491 X 381 * 3616071 -
 해결방안
 1 Time Series Forecasting 모든 종목을 강화학습할순 없기 때문에 다음 일주일 동안 가장 큰종가 변화율을 보일 종목을 예측한다
 2 Reinforcement Learning 분 단위 거래를 학습하여 단타매매를 실행한다 하루에 381개의 분봉 데이터 존재
<p.04>
 [WorkFlow]
 Day Candle Stoch Datd
 LETF
 6 Stock Code듭
 크레온 AP
 Airute Candle EtoC
 A2
<p.05>
 [종목선정 데이터 수집 및 전처리]
 국내 주식 Reader로 데이터 수집 IFinance Data
 수집기간 2017-01-01~ 현재
 수집 항목 종가
 종목 KOSP
<p.06>
 종목선정 데이터 수집 및 전처리]
 2 L09 Transform
<p.07>
 [종목선정 데이터 수집 및 전처리]
 3 계산 RSI Sharpe Ratio
 1} RSI Relative Index Strength
 RSIC%o-=1OO-C1OO/1+RS
 2 Sharpe Ratio
 Sharpe Ratio Rp-Rf/ o p
 Rp: 투자 포트폴리오의 기대 수익률 Rf: 무위험 수익률로 일반적으로 국채나 정부 채권의 수익률을 사용 :포트폴리오 수익률의 표준편차로 투자의 총 위험을 나타냄 Op:
<p.08>
 -시계열 모델] 총목선정
 1Long Short-Term Memory LSTM
 기반의 모델 RNN 장기 의존성 문제를 해결하여 오랜 기간의 데이터 반영 가능
<p.09>
 총목선정 시계열 모델]
 2 Dlinear LSTF-linear
 Transformer 구조 선형 예측 + 기존 Transofrmer에l서의 시간적 정보 손실 방지
<p.10>
 총목선정 모델 평가 및 선정]
 평가 기법
 72
 MSE - 7
 MAE평균 절대 오차
 MSE평균 제곱 오차
 실제 정답 값과 예측 값의 차이를 절댓값으로 변환한 뒤 합산하여 평균을 구함
 실제 정답 값과 예측 값의 차이를 체곱한 뒤 평균을 구함
 LSTM에 대한 MAE: 37084 LSTM에 대한 MSE: 150189
 LSTF에 대한 MAE: 00811 LSTF에 대한 MSE: 00348
<p.11>
 [시스템 수집] 트레이딩 데이터
 대신증권 이용하여 분봉 데이터 최대 AP Creon을 20만개 수집
 대신 증권 AP C 이미 이용 하여 분봉 1이터 최대 20만 개 수접 reon을 최근 0개를 사용 하여 학습 장 |감 후 당일 로추 가 학 분봉 데이터 1500 J 분봉 데이E
 데이터 사용하여 학습 15000개- 를 +장마감후당일 분봉 데이터로 추가 학습 -
 <Creon APl>
 <데이터 예시>
<p.12>
 [시스템 트레이딩 데이터 전처리
 기 적 또 를 저 |공 등 |는 해 든 7 이 딩 에 합 한 TA 지 더 ra r -
 종가와 거래량의 5 10 20 60 120 이동 평균 상한가-종가 1시가-종가 하한가-종가비율 등 과매도 상태를 식별 스토케스틱오실레이터:과매수와 '과열이나 침체 국면 판단 상대강도지수 주가의 변동성을 저점 파악 볼린저밴드: 측정하고 상대적인 고점과 장단기 이동평균선으로 매매 모멘텀 추정 이동평균수렴확산: 가격 주가 추세의 평가 누적체적선 거래량을 고려하여 움직임을 분석하고 강도를 - 가격의 상승 또는 하락 추세의 강도와 지속 시간 측정 AROON 가격 움직임의 평균 변동성을 계산 ATR
<p.13>
 [시스템 트레이딩 데이터 전처리]
 <전처리 후 데이터 예시>
<p.14>
 [시스템 강화학습 모델 트레이딩
 강화학습이란?
 머신러닝의 한 어떠한 어떠 한 행동을 했을때그 종류로 환경에서 것이 잘된 행동인지 잘 못된 행동인지 나중에 판단하고 보상 또는 벌칙을 줌으로 반복을 통해 스스로 학습하게 하는 분야 => 주식투자도 어떠힌 환경에서 매수 buy 매도sell 관망hol 등을 판단하는 문제 로서 강화학습을 적용 할 행동 -> 매수 매도 관망 행동은 신경망으로 결경 성하고 신경망은 에히전트가 수행하는 행동의 결과로 발 생하는 수익 또는 손실의 보상 과 학습 데이터로 학습함 - -
 __ 머신러닝으 종류로 어떠 한 어 떠한 환경에서 행동을 기0< 것을 때 |그것이 잘된 행동인 잘못된 행동 인지 나중에 판단층 |고 보상또는 벌칙을 줌으 굳써 반복을 통 해 스스로 학습 하게 하는 분 야 어떠한 환경 에서 매수bu => 주식투자도 매도sell 관망 hold 미0 을 판단하는 문제로서 강화 학습을 적용할
<p.15>
 [시스템 트레이딩 강화학습 모델]
 강화학습] A2C Advantage Critic 알고리즘 Actor -
 Critic 방 Actor | + Adv: 가 념 ntage Actor는 정책 경사 델을 사용 하여 현재 <0 태에서 어 더 행동을 추 |할지 결정 하는 역할을 하며 Critic은 Q-러닝 모들 빌을 사용하 여 취해진 100 동의 가치를 평가함 Advanta 9e라는 개는 弓을 통해 여 상되는 보성 상과 현재 중 책에 따른 가치 함수 |의 차이를 이용해 액E |의 정책을 업데이트함
 A2C는 Critic을 Advantage로 학습
<p.16>
 [시스템 화면] 트레이딩 테스트
 학습 모델
 a2c cnn 120dim 15000개 분봉데이터 300epochs
 한국투자증권 AP
 11분 단위로 buy Sell hold 예측
 2 Confidence어 따라
 2 따리 Confidence어 주문수량 결정
 3 A미로 주문
 영상 테스트
<p.17>
 [시스템 트레이딩 backtrading
 001470 삼부토건
 002690 동일제강
 포트폴리오 가치
 267260 HD현대일렉트르
 002870 신풍
 011000 진원생명과학
<p.18>
 시스템 결과] 트레이딩
<p.19>
 시스템 트레이딩 한계점
 훈련 과정에서의 과적합
 [001470] RL:a2c IETHCNI! H:0 001 마F:099 EPOLHHOEOEOT EPSILO J:0g
 [001470] RL:a2c IJET:CNIT LA:O OOl DF:099 EPDCH:12미E니! EPSILDM:0 GO
<p.20>
 감사합니다!
 질문이 있으신가요?
