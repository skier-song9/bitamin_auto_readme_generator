<p.01>
 시계열 1조
 비타민 12 & 13기 학기 프로젝트
 피쳐 중요도 통한 분석을 지수 예측 KOSP2O
<p.02>
 비타민 학기 프로젝트 최종 발표 목차
 LEVEL 2 모델 소개 XGB LSTM GRU
 EVEL 3 피쳐 중요도 분석 Attention SHAP
 LEVEL 4 결과 비교 및 결론
<p.03>
 시계열 1조 최종 BITAmin 발표
 피쳐 중요도 분석을 통한 KOSPI 지수 예측
 데이터고개
<p.04>
 코스닥
 DATA
 다우존스
 니케이 225
 상해종합치수
 WTI 원유 가격
 KOSPL20O
 브렌트유 가격
 국제 금 가격
 시카고옵션거래소 변동성치수
 미국 달러 환율
 중국 위안 환율
 일본 엔 환율
<p.05>
 데이터 전처리
 200을 기준으로 데이터프레임 병합 KOSPI
 ex 다우존스의 5월 15일 종가는 우리나라 시간으로 5월 16일
 날짜를 하루 앞당겨서 사용
 날짜 하루씩 조정 Dow [ ['날짜']= to datet Me[ I dow ['날짜']} Od dow'[ edit_날파']- dow['날짜'] + mede Ita OdTi days- - dow Head
 날짜를 하루 앞당긴 변수 다우존스 원/달러 환율 WTI 원 [ 유가격 브렌트유 가격 국제 |금 가격 Vix 지수 -
 df fillnamethod='ffill' inplace=True로 결측치 처리 -~
<p.06>
 BITAmin 시계열 1조 최종 발표
 피쳐 중요도 분석을 통한 KOSP! 지수 예측
 모델고개
 XGBLSTM GRU
<p.07>
 트리 기반의 앙상불 학습 알고리즘 기본 학습기를 의사결정나무 Decision Tree로 하여 그래디언트 부스팅과 같이 그래디언트를 이용해 이전 모형의 약점을 보완하는 방식으로 학습하는 모델
 XGBOOst
 본 프로젝트에서는 이진분류 모델을 구현했으므로 손실함수로 'binary: kOgistic 사용함
 병렬처리가 가능해 빠른 속도로 뛰어난 예측 성능 보임
<p.08>
 슬라이딩 윈도우 방법론
 데이터의 시간적 순서를 유지하며 동시에 과거 데이터를 기반으로 미래를 예측하는 효과적 방법!
 누적된 과거 데이터를 윈도우로 정의 윈도우를 일정 간격으로 이동시키면서 다음 시점의 값을 예측 >
 그림처럼 1명의 고객으로 7개의 분석용 데이터를 얻을 수 있음 A라는 동일한 사람이 A1 A2 A3으로 시간 차를 두고 복제됨으로써 기존에 1000개의 정보가 있었다면 슬라이딩 윈도우 기법을 통해 고객 정보를 확보! 7000건의
 시간 종속성을 유지하며 데이터의 패턴 반영해 모델이 더 많은 정보를 기반으로 학습 예측 가능
 윈도우 크기만큼 데이터의 피쳐가 증가함
<p.09>
 XGBoOst 구축 종가 데이터
 하이퍼 파라미터 튜닝 결과
 learning rate=005 depth=5 n estimators-200 window Size=100 max
 05518의 보임 accuracy를
<p.10>
 구축 XGBOOst 변화율 데이터
 하이퍼 튜닝 결과 파라미터 learning rate=005 depth=5 estimators=100 max n
 06098의 보임 accuracy를
 변화율 데이터를 이용한 모델이 005 정도의 성능 개선을 보임
<p.11>
 긴 시간동안 RNN의 메모리를 유지
 ISTM
 LSTM은 Cell state와 Gate 메커니즘을 통해 긴 시권스 내의 중요 한 정보를 오래 유지하고 불필요한 정보는 잊어버려 장기 의존성 문제를 효과적으로 해결함
 Input Output Forget Gate
 Input Output Forget Gate를 사용하여 시계열 데이터의 중요 한 패턴과 추세를 학습하고 보존함
 시계열 데이터에 효과적인 집러닝 프레임워크
<p.12>
 ESTM 구축
 두 개의 LSTM 레이어를 사용
 각 레이어 후에 드롭아웃을 추가하여 과적합을 방지
 콜백을 사용하여 가장 좋은 가중치를 복원 EarlyStopping
<p.13>
 GRU
 LSTM과 유사하게 게이트 메커니즘을 통해 중요한 정보를 유지하 고 불필요한 정보를 제거함 GRU는 셀 상태 없이 두 개의 Gate만 사용하여 시권스 데이터의 장기 의존성 문제를 효과적으로 해결
 Reset Gate와 Update Gate
 Reset Gate와 Update Gate를 사용하여 시계열 데이터의 중요한 패턴과 추세를 학습하고 보존
 시계열 데이터에 효과적인 덥러닝 프레임워크
<p.14>
 GRU 구축
 두 개의 GRU 레이어를 사용
 각 레이어 후에 드롭아웃을 추가하여 과적합을 방지
 콜백을 사용하여 가장 좋은 가중치를 복원 EarlyStopping
<p.15>
 시계열 1조 최종 발표 BITAmin
 피쳐 중요도 분석을 통한 KOSP! 지수 예측
 피쳐중요도분적 Attention SHAP
<p.16>
 Attention
 중요한 부분에 더 집중Attention 하자!
 Attention 변수 중요도 가중치
 보통 자연어 처리와 컴퓨터 비전 분야에서 사용되는 기술
 가중치는 각 단어의 중요도기여도를 의미한다
 시계열 데이터에 적용하면 특정 시간 단계에서 중요한 정보에 집중
 각 뤄리 벤터와 모든키 벤터 사이의 유사도 를 계산 내적등
 여러 개의 입력 벤터를 받고 그 벤터를 세 종류 벤터로 변환
 Attention 가중치 계산된 유사도 점수를 Softmax 함수에 통과시켜 가중치 생성
 쿼리Query 주어진 문장에서 현재 주목하는 단어를 나타내는 벤터 키Key 각 단어의 특성을 나타내는 벤터 밸류Value: 각 단어의 실제 정보를 나타내는 벤터
 가중합Weighted Sum 각 밸류 벤터에 해당 가중치를 곱한 후 이를 모두 더해 최종 출력 벤터를 만듬
 각 단어의 가중치를 계산하고 반영해 어떤 것에 집중하자
 더높은 가중치를 부여하는 것은 그만큼 더 주의Attention를 기울인다는 것
<p.17>
 Attention
 def bui mode { Iput _Shape embed_dim heads ff_dim  /d 그um Fate- I nput Shape-[ }} I rput = Irput_shape Input_shape }{ 입력 Inputs # 차 X - Dense act I vat 미= Felu ++ Expand ]_d * S-1] # = Add Sequence X Mens On transformer_bIock = TransformerB Dck embed_dim  그um_heads transfor mer 6 Dck [受] = S=1 # Renove = ++ Squeeze! & ax Di Sequence Mels Out puts Dense[ 1}% # Reg = Ion Out put mode | = Mode I nput puts Out put tputs - Fetur mode
 Transformer 블록을 포함한 모델을 정의
 def Get_attent On_we ghtsl model |}: | for I ayer in mode  I ayers: if 15 I nst ance[ Ayer TransformerB| Ock: Fetur ayer att get_weights [O] attent ion_we i ght s = Get_attent io_we i ightsl modeI
 생성 TransfomerBlock
 가중치 추출 Attention
<p.18>
 종가
 변화율
 1 WTI WT| 원유 가격 - 2 DOW 다우존스 산업평균지수 1 3 달러 환율 USD KRW 1
 1 DOW 다우존스 산업평균지수 1 2 SSEC 상해종합치수 3 NIKKE! 니케이 225 평균주가
<p.19>
 SHAP
 게임이론에 기반한 머신러닝 모델의 출력을 설명하기 위한 접근법
 피쳐 중요도 시각화 해석
 상위 20개의 피쳐가 표시되었다 왼 종가 오 변화율
 피처의 중요도: Y축의 순서대로 피처가 모델 예측에 미치는 중요도가 높다 SHAP 값의 크기와 방향: X축에서 SHAP 값의 절대값이 클수록 해당 피처가 모델 예측에 더 큰 영향을 미친다 SHAP 값이 양수이면 해당 피처 값이 클수록 예측 확률이 증가함을 의미하고 음수이면 예측 확률이 감소함을 의미 피쳐 값의 효과: 빨간 색은 피쳐값이 높음 파란색은 피쳐값이 낮음을 의미 빨간 점이 오른쪽에 많이 분포한다면 해당 피쳐 값이 클수록 예측 확률이 증가함을 의미한다
 -> SHAP를 통해서 중요도 상위 피쳐를 찾아낼 수 있었다!
<p.20>
 SHAP XGB
 피쳐 간 상호작용 확인
 A 그| 값 4 Sha alue Tai Sha _in Gt it 50 ter? IGti alue Sha Je & 9| [0] On_! 15 Ter [era n_! I IE | Talpe
<p.21>
 SHAP XGB
 피쳐 간 상호작용 확인
 ->피쳐 간 상호작용의 정도는 미미하였다! 왼: 종가 '오: 변화율
<p.22>
 SHAP XGB
 SHAP 결과 상위 피쳐만 사용하여 모델링_ 종가
 SHAP 변수 중요도 분석 결과 상위 피쳐만 사용하여 모델링 결과
 1300개의 피쳐 window Size=100 중 상위몇 백개만 사용하여 모델링
 1 원래 모델 성능 05518 2 300개의 피쳐만 사용한 결과 성능 052 3 500개의 피쳐만 사용한 결과 성능:05396
 변수 중요도 분석을 통해 중요 변수를 뽑아낸 결과 -> SHAP 훨씬 적은 피쳐만으로도 성능을 비슷하게 유지할 수 있었다!
 *상위 20개의 피쳐에 가중치를 부여하여 모델링도 해보았으나 모델의 성능에 차이가 없음도 발견할 수 있었다
<p.23>
 SHAP XGB
 SHAP 결과 상위 피쳐만 사용하여 모델링 변화율
 SHAP 변수 중요도 분석 결과 상위 피쳐만 사용하여 모델링 결과
 130개의 피쳐 window Size=10 중 상위몇 개만 사용하여 모델링
 1 원래 모델 성능 06098 2 5개의 피쳐만 사용한 결과 성능 05925 3 10개의 피쳐만 사용한 결과 성능 05954
 SHAP 변수 -> 중요도 분석을 통해 중요 변수를 뽑아낸 결과 훨씬 적은 피쳐만으로도 성능을 비슷하게 유지할 수 있었다!
<p.24>
 시계열 1조 최종 BITAmin 발표
 피쳐 중요도 분석을 통한 KOSPI 지수 예측
 결과 1및 비교 - - 결론
<p.25>
 Conclusior
 피쳐 중요도 분석을 통한 지수 예측 모델 성능 비교 KOSPI2OO
 종가 VS 변화율
 Attention을 이용한 Feature mportance
 XGBoOst GRU 간의 ESTM 성능 차이
<p.26>
 결과 비교
 종가와 변화율 사용에 따른 모델 성능 비교
 XGBoOst가 가장 우수한 성능 보여줌
 변화율 데이터에서 성능 향상을 보여줌 변화율 데이터를 사용하여 성능이 향상된 것은 변화율 데이터가 종가 데이터보다 더 유의미한 패턴과 트렌드를 제공함으로써 모델의 예측 정확도를 높이고 노이즈를 줄이며 일반화 능력을 향상시키는 데 효과적임을 확인함
<p.27>
 결과 비교
 변수중요도 적용유무에 따른 모델 성능 비교
 XGBoOst가 가장 우수한 성능 보여줌
 STM이나 GRU에 비해 XGBoOst가 더 높은 성능을 보였다
 attention을 이용한 Feature 적용한 결과: Importance LSTM GRU 성능 증가/ XGB 성능 약간 감소
 LSTM GRU 의 경우 변수중요도를 적용하지 않은 데이터세트보다 변수 중요도를 적용한 데이터 세트에서 약간의 성능 향상을 보임 XGBoOst의 경우 어텐션 결과를 적용한 결과 약간의 성능 하강을 보임
 이는 LSTM과 GRU가 RNN계열의 모델로 어텐션 매커니즘을 적용함으로써 시권스 데이터 내의 중요 정보를 잘 파악할 수있게 하는 반면 XGB는 트리기반의 모델로 피쳐 간 순차적 관계를 고려하는 어텐션 매커니즘 이 오히려 노이즈를 늘릴 수 있기 때문이라고 추정할수 있다
 트리기반 모델은 순차적 피쳐 관계 고려 X
<p.28>
 결과 비교
 변수 중요도 적용 하는 방법에 따른 모델 성능 비교
 Xgboost와 LSTM이 각각 우수한 성능 보여줌
 변수 중요도 계수를 적용한 데이터세트에서는 Xgboost가 변수 중요도가 양수인 계수만 적용한 데이터세트에서는 LSTM이 우수한 성능을 보여줌
 변수 중요도 계수 적용한 경우 성능이 가장 우수
 각 변수의 중요도를 곱한 데이터에서 모델의 성능이 가장 우수함 변수 중요도 양수값만 적용한 경우약 001의 성능이 감소함 음수가 나온 칼럼들이 원래 데이터의 절반정도임을 고려하였을 때 의미있는 결과로 볼 수 있음
<p.29>
 결론
 종가 VS 변화율 데이터
 Attention 매커니즘 활용 변수 중요도 분석
 변화율 데이터가 데이터의 잡음을 줄이고 추세성을 반영함으로써 종가 데이터보다 정확한 성능을 보인다 -> 주가 예측에서는 변화율 데이터를 사용하는 것이 좋다
 매커니즘을 활용해 변수 중요도 가중치를 얻을 수 있다 LSTM GRU의 예측 성능이 증가했다 Attention 변수 중요도 정보로 시계열 분석에서의 RNN 계열 모델 정확도를 올릴 수 있다
 변수 중요도 분석 의의
 변수 분석을 통해 모델의 중요도 성능의 개선을 꾀할 수 있다 변수 중요도 분석을 통해 변수 선택 Feature Selection을 적용하여 적은 피쳐만으로도 모델의 성능을 유지할 수 있다 주가 예측에서 데이터의 피쳐가 많을 경우의 처리가 용이하다
<p.30>
 감사합니다
 BITAmin 시계열 1조
